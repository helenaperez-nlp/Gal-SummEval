{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13970127,"sourceType":"datasetVersion","datasetId":8906005},{"sourceId":14191599,"sourceType":"datasetVersion","datasetId":9049029},{"sourceId":14191605,"sourceType":"datasetVersion","datasetId":9049035}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"WANDB_MODE\"] = \"disabled\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:13:01.626992Z","iopub.execute_input":"2025-12-23T15:13:01.627218Z","iopub.status.idle":"2025-12-23T15:13:01.633414Z","shell.execute_reply.started":"2025-12-23T15:13:01.627196Z","shell.execute_reply":"2025-12-23T15:13:01.632847Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Try to avoid OOM error when training the model\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T16:00:48.090509Z","iopub.execute_input":"2025-12-23T16:00:48.091303Z","iopub.status.idle":"2025-12-23T16:00:48.094772Z","shell.execute_reply.started":"2025-12-23T16:00:48.091268Z","shell.execute_reply":"2025-12-23T16:00:48.094067Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"!pip install --upgrade unsloth peft bitsandbytes accelerate trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:13:01.635163Z","iopub.execute_input":"2025-12-23T15:13:01.635390Z","iopub.status.idle":"2025-12-23T15:15:43.994567Z","shell.execute_reply.started":"2025-12-23T15:13:01.635371Z","shell.execute_reply":"2025-12-23T15:15:43.993829Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.12.9-py3-none-any.whl.metadata (65 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\nCollecting peft\n  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nCollecting accelerate\n  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\nCollecting trl\n  Downloading trl-0.26.2-py3-none-any.whl.metadata (11 kB)\nCollecting unsloth_zoo>=2025.12.7 (from unsloth)\n  Downloading unsloth_zoo-2025.12.7-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.8.0+cu126)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.23.0+cu126)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\nCollecting tyro (from unsloth)\n  Downloading tyro-1.0.3-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.4.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\nCollecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth)\n  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.2)\nRequirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.57.1)\nCollecting trl\n  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.3)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.20.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\nCollecting multiprocess<0.70.17 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\nCollecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (0.22.1)\nCollecting torchao>=0.13.0 (from unsloth_zoo>=2025.12.7->unsloth)\n  Downloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.12.7->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.7->unsloth) (11.3.0)\nCollecting msgspec (from unsloth_zoo>=2025.12.7->unsloth)\n  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.10.2.21->torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.1.2->torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nccl-cu12==2.27.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.0.4->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (0.17.0)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\nDownloading unsloth-2025.12.9-py3-none-any.whl (376 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.18.0-py3-none-any.whl (556 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.12.7-py3-none-any.whl (290 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m290.7/290.7 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-1.0.3-py3-none-any.whl (180 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torchao, triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multiprocess, msgspec, fsspec, tyro, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, accelerate, trl, peft, unsloth_zoo, unsloth\n  Attempting uninstall: torchao\n    Found existing installation: torchao 0.10.0\n    Uninstalling torchao-0.10.0:\n      Successfully uninstalled torchao-0.10.0\n  Attempting uninstall: triton\n    Found existing installation: triton 3.4.0\n    Uninstalling triton-3.4.0:\n      Successfully uninstalled triton-3.4.0\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.6.77\n    Uninstalling nvidia-nvtx-cu12-12.6.77:\n      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n  Attempting uninstall: nvidia-nvshmem-cu12\n    Found existing installation: nvidia-nvshmem-cu12 3.4.5\n    Uninstalling nvidia-nvshmem-cu12-3.4.5:\n      Successfully uninstalled nvidia-nvshmem-cu12-3.4.5\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.27.3\n    Uninstalling nvidia-nccl-cu12-2.27.3:\n      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufile-cu12\n    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.18\n    Uninstalling multiprocess-0.70.18:\n      Successfully uninstalled multiprocess-0.70.18\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.10.0\n    Uninstalling fsspec-2025.10.0:\n      Successfully uninstalled fsspec-2025.10.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.8.0+cu126\n    Uninstalling torch-2.8.0+cu126:\n      Successfully uninstalled torch-2.8.0+cu126\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.4.1\n    Uninstalling datasets-4.4.1:\n      Successfully uninstalled datasets-4.4.1\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.23.0+cu126\n    Uninstalling torchvision-0.23.0+cu126:\n      Successfully uninstalled torchvision-0.23.0+cu126\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.11.0\n    Uninstalling accelerate-1.11.0:\n      Successfully uninstalled accelerate-1.11.0\n  Attempting uninstall: peft\n    Found existing installation: peft 0.17.1\n    Uninstalling peft-0.17.1:\n      Successfully uninstalled peft-0.17.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nfastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.1 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\ntorchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-1.12.0 bitsandbytes-0.49.0 cut_cross_entropy-25.1.1 datasets-4.3.0 fsspec-2025.9.0 msgspec-0.20.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 peft-0.18.0 torch-2.9.1 torchao-0.15.0 torchvision-0.24.1 triton-3.5.1 trl-0.24.0 tyro-1.0.3 unsloth-2025.12.9 unsloth_zoo-2025.12.7 xformers-0.0.33.post2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:15:43.995757Z","iopub.execute_input":"2025-12-23T15:15:43.996018Z","iopub.status.idle":"2025-12-23T15:15:47.798127Z","shell.execute_reply.started":"2025-12-23T15:15:43.995988Z","shell.execute_reply":"2025-12-23T15:15:47.797474Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\nRequirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.6\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **IMPORTS**","metadata":{}},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:15:47.799324Z","iopub.execute_input":"2025-12-23T15:15:47.799882Z","iopub.status.idle":"2025-12-23T15:16:22.485475Z","shell.execute_reply.started":"2025-12-23T15:15:47.799853Z","shell.execute_reply":"2025-12-23T15:16:22.484880Z"}},"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-12-23 15:15:54.975426: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766502955.153804      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766502955.205987      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766502955.629769      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766502955.629798      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766502955.629801      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766502955.629803      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import scipy\nimport json\nimport re\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nimport evaluate\nfrom scipy.stats import spearmanr, kendalltau\nfrom datasets import Dataset\nfrom tqdm import tqdm\nimport glob\n\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling, EarlyStoppingCallback\nfrom peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training, PeftModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:16:22.486294Z","iopub.execute_input":"2025-12-23T15:16:22.487023Z","iopub.status.idle":"2025-12-23T15:16:22.663864Z","shell.execute_reply.started":"2025-12-23T15:16:22.486991Z","shell.execute_reply":"2025-12-23T15:16:22.663021Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# **CARGO LOS DATOS**","metadata":{}},{"cell_type":"code","source":"def load_jsonl(path):\n    data = []\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                data.append(json.loads(line))\n        return pd.DataFrame(data)\n    except FileNotFoundError:\n        print(f\"Error: No se encontrÃ³ el archivo {path}\")\n        return pd.DataFrame()\n\ndf_es = load_jsonl(\"/kaggle/input/basse-es-jsonl/BASSE_es.jsonl\")\n#df_eu = load_jsonl(\"/kaggle/input/basse-eu-jsonl/BASSE_eu.jsonl\")\ndf_test_gl = load_jsonl(\"/kaggle/input/basse-gl-jsonl/BASSE.gl.jsonl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:16:22.664895Z","iopub.execute_input":"2025-12-23T15:16:22.665214Z","iopub.status.idle":"2025-12-23T15:16:22.736576Z","shell.execute_reply.started":"2025-12-23T15:16:22.665186Z","shell.execute_reply":"2025-12-23T15:16:22.736085Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# **DIVIDO EL CONJUNTO DE DATOS**","metadata":{}},{"cell_type":"code","source":"# 1 -> Separamos test sets para ES (10%)\n#train_dev_es, test_es = train_test_split(df_es, test_size=0.1, random_state=42, shuffle=True)\ntrain_dev_es, test_es = train_test_split(df_es, test_size=0.2, random_state=42, shuffle=True)\n# 2 -> Creamos train sets (80% total) y dev sets (10% total) para ES y EU\n#train_es, dev_es = train_test_split(train_dev_es, test_size=0.1111, random_state=42, shuffle=True)\ntrain_es, dev_es = train_test_split(train_dev_es, test_size=8/36, random_state=42, shuffle=True)\n\n# 3 -> Ajustamos el tamaÃ±o del train set (train_set_length ==> modeloES = modeloEU = modeloES-EU)\n#train_es_fewshot = train_es.head(20)\n#train_eu_fewshot = train_eu.head(20)\n\n# 4 -> Shuffle ES + EU\ndf_train = train_es\ndf_dev = dev_es\n\n# 5 -> Ponemos nombres claros a los test\ndf_test_es = test_es.reset_index(drop=True)\n# df_test_gl \n\nprint(f\"TRAIN:    {len(df_train)}\")\nprint(f\"DEV:      {len(df_dev)}\")\nprint(\"-\" * 30)\nprint(f\"TEST ES:  {len(df_test_es)}\")\nprint(f\"TEST GL:  {len(df_test_gl)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:16:22.738856Z","iopub.execute_input":"2025-12-23T15:16:22.739147Z","iopub.status.idle":"2025-12-23T15:16:22.756542Z","shell.execute_reply.started":"2025-12-23T15:16:22.739121Z","shell.execute_reply":"2025-12-23T15:16:22.755702Z"}},"outputs":[{"name":"stdout","text":"TRAIN:    28\nDEV:      8\n------------------------------\nTEST ES:  9\nTEST GL:  15\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# **COMO UN RESUMEN TIENE MAS DE UNA ANOTACIÃ“N, HAGO LA MEDIA**","metadata":{}},{"cell_type":"code","source":"def extraer_resumenes(df):\n    res = []\n\n    for _, row in df.iterrows():\n        original = row.get('original_document', '')\n        \n        model_data = row.get('model_summaries', {})\n        \n        if isinstance(model_data, dict):\n            for model_name, contenido in model_data.items():\n                summary = contenido.get(\"summ\", None)\n                anns = contenido.get(\"anns\", {})\n                \n                consistency_vals = anns.get(\"Consistency\", None)\n\n                if summary and consistency_vals:\n                    if isinstance(consistency_vals, list):\n                        score = np.mean(consistency_vals)\n                    else:\n                        score = float(consistency_vals)\n                        \n                    media = int(round(score))\n                    \n                    res.append((summary, media, original))\n\n    return pd.DataFrame(res, columns=[\"summary\", \"consistency\", \"original_document\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:16:22.757710Z","iopub.execute_input":"2025-12-23T15:16:22.757983Z","iopub.status.idle":"2025-12-23T15:16:22.772391Z","shell.execute_reply.started":"2025-12-23T15:16:22.757925Z","shell.execute_reply":"2025-12-23T15:16:22.771675Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df_train_redondeo = extraer_resumenes(df_train)\ndf_dev_redondeo = extraer_resumenes(df_dev)\ndf_test_es_redondeo = extraer_resumenes(df_test_es)\ndf_test_gl_redondeo = extraer_resumenes(df_test_gl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:16:22.773216Z","iopub.execute_input":"2025-12-23T15:16:22.773448Z","iopub.status.idle":"2025-12-23T15:16:22.801754Z","shell.execute_reply.started":"2025-12-23T15:16:22.773424Z","shell.execute_reply":"2025-12-23T15:16:22.801145Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(f\"Ejemplos procesados TRAIN: {len(df_train_redondeo)}\")\nprint(f\"Ejemplos procesados DEV: {len(df_dev_redondeo)}\")\nprint(f\"Ejemplos procesados TEST es: {len(df_test_es_redondeo)}\")\nprint(f\"Ejemplos procesados TEST gl: {len(df_test_gl_redondeo)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:16:22.802554Z","iopub.execute_input":"2025-12-23T15:16:22.802884Z","iopub.status.idle":"2025-12-23T15:16:22.807015Z","shell.execute_reply.started":"2025-12-23T15:16:22.802846Z","shell.execute_reply":"2025-12-23T15:16:22.806357Z"}},"outputs":[{"name":"stdout","text":"Ejemplos procesados TRAIN: 624\nEjemplos procesados DEV: 168\nEjemplos procesados TEST es: 198\nEjemplos procesados TEST gl: 150\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# **CONSTRUYO EL PROMPT**","metadata":{}},{"cell_type":"code","source":"def construct_metric_prompt_simple(row, target_metric):\n    \"\"\"Construye un prompt de instrucciÃ³n para evaluar un resumen usando una mÃ©trica especÃ­fica\"\"\"\n    \n    summary = row['summary']\n    original_document = row['original_document']\n    score = row[target_metric]\n    \n    prompt = f\"\"\"[INSTRUCCIÃ“N]\nAs an expert evaluator, analyze the following summary.\nEvaluate solely the {target_metric} criterion on a scale of 1 to 5, where 1 is the lowest score and 5 is the highest.\n\nCriterion: Consistency: the factual alignment between the summary and the summarized source. A factually consistent summary contains only statements that are entailed by the source document. Annotators were also asked to penalize summaries that contained hallucinated facts. That is to say, does the summary hallucinate or make up information? If the summary contains information not found in the original document, we penalize it. For temporal expressions (today, yesterday, this year), if the expression is consistent with the original information, we assume that the summary is consistent and do not penalize.\",\n\nScore 1: The summary does not contain any ideas from the original text.\nScore 2: The summary contains a large amount of incorrect information.\nScore 3: The summary contains several incorrect pieces of information.\nScore 4: The summary contains once incorrect piece of information.\t\nScore 5: The summary is completely factual.\n\nProvide only the score for the criterion indicated below in the exact format. **Do not add any justification, explanation, or additional text**, just the score.\n\nExpected output format:\n- [CONSISTENCY]: score\n\n[SUMMARY] This is the summary to evaluate:\n{summary}\n\n[ORIGINAL DOCUMENT] This is the original document on which the summary is based.\n    {original_document}\n\nProvide your evaluation in the exact format: [CONSISTENCY]: (N) where N is a number from 1 to 5\n\"\"\"\n    \n    response = f\"[{target_metric.upper()}]: {int(round(score))}\"\n    return {\"prompt\": prompt, \"completion\": response}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:33:20.206208Z","iopub.execute_input":"2025-12-23T15:33:20.206525Z","iopub.status.idle":"2025-12-23T15:33:20.211728Z","shell.execute_reply.started":"2025-12-23T15:33:20.206494Z","shell.execute_reply":"2025-12-23T15:33:20.211041Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# FunciÃ³n prepare_metric_dataset ahora puede usar los 3 test sets\ndef prepare_metric_datasets(df_train, df_dev, df_test_es, df_test_gl, target_metric):\n    def build_data(df, split_name):\n        data = []\n        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Preparando {split_name} para {target_metric}\"):\n            data.append(construct_metric_prompt_simple(row, target_metric))\n        return data\n\n    train_data = build_data(df_train, \"train\")\n    dev_data = build_data(df_dev, \"dev\")\n    test_es_data = build_data(df_test_es, \"test_es\")\n    test_gl_data = build_data(df_test_gl, \"test_gl\")\n\n\n    train_dataset = Dataset.from_dict({\n        \"prompt\": [d[\"prompt\"] for d in train_data],\n        \"completion\": [d[\"completion\"] for d in train_data]\n    })\n    \n    dev_dataset = Dataset.from_dict({\n        \"prompt\": [d[\"prompt\"] for d in dev_data],\n        \"completion\": [d[\"completion\"] for d in dev_data]\n    })\n    \n    test_es_dataset = Dataset.from_dict({\n        \"prompt\": [d[\"prompt\"] for d in test_es_data],\n        \"completion\": [d[\"completion\"] for d in test_es_data]\n    })\n\n \n    test_gl_dataset = Dataset.from_dict({\n        \"prompt\": [d[\"prompt\"] for d in test_gl_data],\n        \"completion\": [d[\"completion\"] for d in test_gl_data]\n    })\n\n    return train_dataset, dev_dataset, test_es_dataset, test_gl_dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:33:22.146362Z","iopub.execute_input":"2025-12-23T15:33:22.146899Z","iopub.status.idle":"2025-12-23T15:33:22.153625Z","shell.execute_reply.started":"2025-12-23T15:33:22.146867Z","shell.execute_reply":"2025-12-23T15:33:22.152899Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"target_metric = \"consistency\"\n#train_dataset, dev_dataset, test_dataset = prepare_metric_datasets(df_train_redondeo, df_dev_redondeo, df_test_redondeo, target_metric)\ntrain_dataset, dev_dataset, test_es_dataset,test_gl_dataset = prepare_metric_datasets(df_train_redondeo, df_dev_redondeo, df_test_es_redondeo, df_test_gl_redondeo, target_metric)\n\nprint(f\"\\nDataset de entrenamiento: {len(train_dataset)} ejemplos\")\nprint(f\"Dataset de desarrollo: {len(dev_dataset)} ejemplos\")\nprint(f\"Dataset de prueba es: {len(test_es_dataset)} ejemplos\")\nprint(f\"Dataset de prueba gl: {len(test_gl_dataset)} ejemplos\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:33:27.760207Z","iopub.execute_input":"2025-12-23T15:33:27.760929Z","iopub.status.idle":"2025-12-23T15:33:27.914742Z","shell.execute_reply.started":"2025-12-23T15:33:27.760880Z","shell.execute_reply":"2025-12-23T15:33:27.914019Z"}},"outputs":[{"name":"stderr","text":"Preparando train para consistency: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 624/624 [00:00<00:00, 19864.04it/s]\nPreparando dev para consistency: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 168/168 [00:00<00:00, 19694.87it/s]\nPreparando test_es para consistency: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198/198 [00:00<00:00, 18181.41it/s]\nPreparando test_gl para consistency: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:00<00:00, 21621.61it/s]","output_type":"stream"},{"name":"stdout","text":"\nDataset de entrenamiento: 624 ejemplos\nDataset de desarrollo: 168 ejemplos\nDataset de prueba es: 198 ejemplos\nDataset de prueba gl: 150 ejemplos\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# **CARGO EL MODELO**","metadata":{}},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/mistral-7b-bnb-4bit\", \n    max_seq_length = 4500,\n    dtype = None,\n    load_in_4bit = True,  \n)\nFastLanguageModel.for_training(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T16:24:59.539404Z","iopub.execute_input":"2025-12-23T16:24:59.540139Z","iopub.status.idle":"2025-12-23T16:25:04.041381Z","shell.execute_reply.started":"2025-12-23T16:24:59.540102Z","shell.execute_reply":"2025-12-23T16:25:04.040250Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.12.9: Fast Mistral patching. Transformers: 4.57.1.\n   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1842987118.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model, tokenizer = FastLanguageModel.from_pretrained(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"unsloth/mistral-7b-bnb-4bit\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mload_in_4bit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/loader.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, load_in_16bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, offload_embedding, float32_mixed_precision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, qat_scheme, load_in_fp8, unsloth_tiled_mlp, *args, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mfast_inference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_inference_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         model, tokenizer = dispatch_model.from_pretrained(\n\u001b[0m\u001b[1;32m    535\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/mistral.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     ):\n\u001b[0;32m--> 454\u001b[0;31m         return FastLlamaModel.from_pretrained(\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, revision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, unsloth_vllm_standby, num_labels, qat_scheme, **kwargs)\u001b[0m\n\u001b[1;32m   2316\u001b[0m             )\n\u001b[1;32m   2317\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfast_inference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m             model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m   2319\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m                 \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5027\u001b[0m         \u001b[0;31m# Prepare the full device map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5028\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5029\u001b[0;31m             \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_in_fp32_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5031\u001b[0m         \u001b[0;31m# Finalize model weight initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_get_device_map\u001b[0;34m(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m             \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"disk\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    128\u001b[0m                     \u001b[0;34m\"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0;34m\"quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "],"ename":"ValueError","evalue":"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ","output_type":"error"}],"execution_count":29},{"cell_type":"code","source":"#from kaggle_secrets import UserSecretsClient\n#user_secrets = UserSecretsClient()\n#secret_value_0 = user_secrets.get_secret(\"wandb\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T15:33:51.400548Z","iopub.execute_input":"2025-12-23T15:33:51.400855Z","iopub.status.idle":"2025-12-23T15:33:51.403992Z","shell.execute_reply.started":"2025-12-23T15:33:51.400816Z","shell.execute_reply":"2025-12-23T15:33:51.403475Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 8, \n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, #0.1\n    bias = \"none\",    \n    use_gradient_checkpointing = \"unsloth\", \n    random_state = 3407,\n    use_rslora = False,  \n    loftq_config = None, \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T16:25:04.041866Z","iopub.status.idle":"2025-12-23T16:25:04.042174Z","shell.execute_reply.started":"2025-12-23T16:25:04.042041Z","shell.execute_reply":"2025-12-23T16:25:04.042059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T16:25:05.707656Z","iopub.execute_input":"2025-12-23T16:25:05.708007Z","iopub.status.idle":"2025-12-23T16:25:05.719687Z","shell.execute_reply.started":"2025-12-23T16:25:05.707943Z","shell.execute_reply":"2025-12-23T16:25:05.719077Z"}},"outputs":[{"name":"stdout","text":"trainable params: 20,971,520 || all params: 7,262,703,616 || trainable%: 0.2888\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"def preprocess(example):\n    prompt = example[\"prompt\"].strip()\n    completion = example[\"completion\"].strip()\n\n    full_text = f\"{prompt}\\n### Completion:\\n{completion}\"\n    input_text = f\"{prompt}\\n### Completion:\\n\"\n\n    tokenized = tokenizer(full_text, return_tensors=\"pt\", padding=False, truncation=True)\n    input_ids = tokenized[\"input_ids\"][0]\n    attention_mask = tokenized[\"attention_mask\"][0]\n\n    labels = input_ids.clone()\n    prompt_len = len(tokenizer(input_text, return_tensors=\"pt\").input_ids[0])\n    labels[:prompt_len] = -100 \n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels,\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T16:25:06.600374Z","iopub.execute_input":"2025-12-23T16:25:06.601110Z","iopub.status.idle":"2025-12-23T16:25:06.605835Z","shell.execute_reply.started":"2025-12-23T16:25:06.601077Z","shell.execute_reply":"2025-12-23T16:25:06.605163Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"train_dataset = train_dataset.map(preprocess)\ndev_dataset = dev_dataset.map(preprocess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T16:25:07.766177Z","iopub.execute_input":"2025-12-23T16:25:07.766703Z","iopub.status.idle":"2025-12-23T16:25:14.789827Z","shell.execute_reply.started":"2025-12-23T16:25:07.766673Z","shell.execute_reply":"2025-12-23T16:25:14.789249Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/624 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d4cec119ec5458fa3e564374c8d110a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/168 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24bc0e2fe4f2490bb54648d61f18c7fd"}},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"class DataCollator:\n    def __call__(self, features):\n        # Asegurar que todos son tensores\n        input_ids = [torch.tensor(f[\"input_ids\"], dtype=torch.long) for f in features]\n        attention_mask = [torch.tensor(f[\"attention_mask\"], dtype=torch.long) for f in features]\n        labels = [torch.tensor(f[\"labels\"], dtype=torch.long) for f in features]\n\n        input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n        attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n        labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n\n        return {\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            \"labels\": labels,\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T16:25:14.791251Z","iopub.execute_input":"2025-12-23T16:25:14.791553Z","iopub.status.idle":"2025-12-23T16:25:14.797385Z","shell.execute_reply.started":"2025-12-23T16:25:14.791527Z","shell.execute_reply":"2025-12-23T16:25:14.796767Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"outputs\",\n    per_device_train_batch_size=1, #2 \n    gradient_accumulation_steps=8, #4\n    per_device_eval_batch_size=1,         # I added this\n    eval_accumulation_steps=10,            # I added this: Move eval results to CPU periodically\n    gradient_checkpointing=True, # I added this. O meu input Ã© longo e non quero erro OOM\n    learning_rate=5e-5,\n    num_train_epochs=3,\n    fp16=True,\n    bf16=False,\n    logging_steps=1,\n    eval_strategy=\"steps\",    \n    eval_steps=20,\n    save_strategy=\"steps\",          \n    save_steps=20,\n    save_total_limit=1,             \n    load_best_model_at_end=True,   \n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=None,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=dev_dataset,\n    data_collator=DataCollator(),\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T16:25:14.798355Z","iopub.execute_input":"2025-12-23T16:25:14.798587Z","iopub.status.idle":"2025-12-23T16:25:14.853061Z","shell.execute_reply.started":"2025-12-23T16:25:14.798562Z","shell.execute_reply":"2025-12-23T16:25:14.852345Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"# **ENTRENO EL MODELO**","metadata":{}},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T16:25:14.854234Z","iopub.execute_input":"2025-12-23T16:25:14.854453Z","iopub.status.idle":"2025-12-23T18:43:21.387790Z","shell.execute_reply.started":"2025-12-23T16:25:14.854428Z","shell.execute_reply":"2025-12-23T18:43:21.387040Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 624 | Num Epochs = 3 | Total steps = 234\nO^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 8 x 1) = 8\n \"-____-\"     Trainable parameters = 20,971,520 of 7,262,703,616 (0.29% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='120' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [120/234 2:16:59 < 2:12:20, 0.01 it/s, Epoch 1/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.082600</td>\n      <td>0.068973</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.079100</td>\n      <td>0.074967</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.065300</td>\n      <td>0.076403</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.104100</td>\n      <td>0.076573</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.062600</td>\n      <td>0.076552</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.069400</td>\n      <td>0.076490</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"# **GUARDO EL MODELO ENTRENADO**","metadata":{}},{"cell_type":"code","source":"trainer.save_model(\"./output/final_model\")\ntokenizer.save_pretrained(\"./output/final_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:43:21.389323Z","iopub.execute_input":"2025-12-23T18:43:21.389613Z","iopub.status.idle":"2025-12-23T18:43:21.753142Z","shell.execute_reply.started":"2025-12-23T18:43:21.389586Z","shell.execute_reply":"2025-12-23T18:43:21.752528Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"('./output/final_model/tokenizer_config.json',\n './output/final_model/special_tokens_map.json',\n './output/final_model/tokenizer.model',\n './output/final_model/added_tokens.json',\n './output/final_model/tokenizer.json')"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name =  \"./output/final_model\",\n    max_seq_length = 5000,\n    load_in_4bit = True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:43:21.753977Z","iopub.execute_input":"2025-12-23T18:43:21.754326Z","iopub.status.idle":"2025-12-23T18:43:34.575115Z","shell.execute_reply.started":"2025-12-23T18:43:21.754300Z","shell.execute_reply":"2025-12-23T18:43:34.574503Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.12.9: Fast Mistral patching. Transformers: 4.57.1.\n   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"name":"stderr","text":"Unsloth: Will load ./output/final_model as a legacy tokenizer.\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"# **LAS REFERENCIAS**","metadata":{}},{"cell_type":"code","source":"def get_references(eval_dataset):\n    respuestas = []\n    for x in eval_dataset:\n        respuesta = [x[\"response\"]]\n        match = re.search(r\"\\[CONSISTENCY\\]:\\s*(\\d+)\", respuesta[0])\n        if match:\n            respuestas.append(int(match.group(1)))\n        else: \n            respuestas.append(None)\n\n    return respuestas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:43:34.576584Z","iopub.execute_input":"2025-12-23T18:43:34.576811Z","iopub.status.idle":"2025-12-23T18:43:34.581201Z","shell.execute_reply.started":"2025-12-23T18:43:34.576787Z","shell.execute_reply":"2025-12-23T18:43:34.580505Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"test_eval_dataset_es = []\nfor i in range(len(test_es_dataset)):\n    test_eval_dataset_es.append({\n        \"prompt\": test_es_dataset[i][\"prompt\"],\n        \"response\": test_es_dataset[i][\"completion\"]\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:43:34.582180Z","iopub.execute_input":"2025-12-23T18:43:34.582428Z","iopub.status.idle":"2025-12-23T18:43:34.626169Z","shell.execute_reply.started":"2025-12-23T18:43:34.582388Z","shell.execute_reply":"2025-12-23T18:43:34.625609Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"referencias_es = get_references(test_eval_dataset_es)\nprint(\"Referencias ES:\", referencias_es)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:43:34.627094Z","iopub.execute_input":"2025-12-23T18:43:34.627329Z","iopub.status.idle":"2025-12-23T18:43:34.638359Z","shell.execute_reply.started":"2025-12-23T18:43:34.627305Z","shell.execute_reply":"2025-12-23T18:43:34.637746Z"}},"outputs":[{"name":"stdout","text":"Referencias ES: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 5, 3, 4, 4, 4, 4, 5, 3, 4, 5, 5, 4, 4, 5, 4, 4, 5, 5, 4, 3, 4, 5, 5, 5, 5, 4, 5, 5, 4, 5, 4, 4, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 2, 4, 3, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 5, 5, 4, 5, 4, 5, 5, 4]\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"test_eval_dataset_gl = []\nfor i in range(len(test_gl_dataset)):\n    test_eval_dataset_gl.append({\n        \"prompt\": test_gl_dataset[i][\"prompt\"],\n        \"response\": test_gl_dataset[i][\"completion\"]\n    })\n    \nreferencias_gl = get_references(test_eval_dataset_gl)\nprint(\"Referencias GL:\", referencias_gl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:43:34.639300Z","iopub.execute_input":"2025-12-23T18:43:34.639793Z","iopub.status.idle":"2025-12-23T18:43:34.671729Z","shell.execute_reply.started":"2025-12-23T18:43:34.639766Z","shell.execute_reply":"2025-12-23T18:43:34.671161Z"}},"outputs":[{"name":"stdout","text":"Referencias GL: [5, 4, 5, 2, 4, 4, 5, 5, 5, 3, 4, 4, 3, 3, 3, 4, 5, 4, 4, 5, 5, 5, 5, 2, 2, 2, 5, 5, 5, 4, 5, 4, 5, 3, 4, 5, 5, 4, 5, 5, 5, 5, 5, 3, 4, 4, 5, 5, 5, 5, 5, 5, 4, 4, 2, 3, 5, 5, 5, 5, 4, 5, 5, 2, 1, 4, 5, 5, 5, 5, 5, 5, 5, 2, 3, 2, 5, 5, 5, 5, 4, 4, 5, 2, 3, 4, 5, 5, 5, 5, 4, 4, 5, 1, 3, 4, 5, 5, 5, 5, 5, 5, 5, 1, 2, 2, 5, 5, 5, 5, 5, 5, 4, 1, 4, 4, 5, 5, 5, 1, 5, 5, 5, 1, 4, 1, 5, 5, 5, 5, 5, 4, 5, 1, 2, 4, 5, 5, 5, 5, 5, 4, 5, 2, 4, 3, 5, 4, 4, 5]\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"# **EVALUO EL MODELO**","metadata":{}},{"cell_type":"code","source":"def evaluate_metric_model(model, dataset, tokenizer, metric):\n    all_predictions = []\n    model.eval()\n    all_predictions = []\n    all_references = []\n\n    \n    # Iterate over the dataset\n    for idx, example in enumerate(tqdm(dataset, desc=f\"Evaluating {metric} model\")):\n\n        prompt = example[\"prompt\"] \n        \n        inputs = tokenizer(\n            prompt,\n            return_tensors=\"pt\",\n            truncation=True,\n            max_length=5000,\n            padding=True\n        )\n        inputs = inputs.to(model.device)\n        with torch.no_grad():\n            outputs = model.generate(\n                input_ids=inputs[\"input_ids\"],\n                attention_mask=inputs[\"attention_mask\"],\n                max_new_tokens=50,\n                do_sample=False,  # GeneraciÃ³n determinista (greedy)\n                pad_token_id=tokenizer.eos_token_id\n            )\n        \n        prompt_length = len(inputs[\"input_ids\"][0])\n        new_tokens = outputs[0][prompt_length:]\n        generated_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n        match = re.search(r\"\\[CONSISTENCY\\]:\\s*(\\d+)\", generated_text)\n        print(generated_text)\n        if match:\n            all_predictions.append(float(match.group(1)))\n        else:\n            all_predictions.append(None)\n\n    \n    return all_predictions\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:43:34.672634Z","iopub.execute_input":"2025-12-23T18:43:34.673046Z","iopub.status.idle":"2025-12-23T18:43:34.684171Z","shell.execute_reply.started":"2025-12-23T18:43:34.673020Z","shell.execute_reply":"2025-12-23T18:43:34.683324Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"# **TEST ES**","metadata":{}},{"cell_type":"code","source":"predictions_es = evaluate_metric_model(model, test_es_dataset,  tokenizer, \"Consistency\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:43:34.685040Z","iopub.execute_input":"2025-12-23T18:43:34.685321Z","iopub.status.idle":"2025-12-23T18:53:44.896344Z","shell.execute_reply.started":"2025-12-23T18:43:34.685297Z","shell.execute_reply":"2025-12-23T18:53:44.895700Z"}},"outputs":[{"name":"stderr","text":"Evaluating Consistency model:   1%|          | 1/198 [00:02<08:15,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   1%|          | 2/198 [00:04<07:15,  2.22s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   2%|â–         | 3/198 [00:06<06:57,  2.14s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   2%|â–         | 4/198 [00:08<06:47,  2.10s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   3%|â–         | 5/198 [00:10<06:43,  2.09s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   3%|â–         | 6/198 [00:12<06:36,  2.06s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   4%|â–         | 7/198 [00:14<06:42,  2.11s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   4%|â–         | 8/198 [00:17<06:45,  2.14s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   5%|â–         | 9/198 [00:19<06:43,  2.13s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   5%|â–Œ         | 10/198 [00:21<06:41,  2.13s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   6%|â–Œ         | 11/198 [00:23<06:57,  2.23s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   6%|â–Œ         | 12/198 [00:26<06:53,  2.22s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   7%|â–‹         | 13/198 [00:28<06:50,  2.22s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   7%|â–‹         | 14/198 [00:30<06:44,  2.20s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   8%|â–Š         | 15/198 [00:32<06:57,  2.28s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   8%|â–Š         | 16/198 [00:35<06:50,  2.26s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   9%|â–Š         | 17/198 [00:37<06:47,  2.25s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   9%|â–‰         | 18/198 [00:39<06:43,  2.24s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  10%|â–‰         | 19/198 [00:41<06:54,  2.32s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  10%|â–ˆ         | 20/198 [00:43<06:32,  2.20s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  11%|â–ˆ         | 21/198 [00:45<06:14,  2.11s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  11%|â–ˆ         | 22/198 [00:50<08:21,  2.85s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  12%|â–ˆâ–        | 23/198 [00:55<09:52,  3.39s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  12%|â–ˆâ–        | 24/198 [00:59<10:48,  3.73s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  13%|â–ˆâ–        | 25/198 [01:04<11:22,  3.95s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  13%|â–ˆâ–        | 26/198 [01:08<11:57,  4.17s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  14%|â–ˆâ–        | 27/198 [01:13<12:01,  4.22s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  14%|â–ˆâ–        | 28/198 [01:17<12:07,  4.28s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  15%|â–ˆâ–        | 29/198 [01:22<12:16,  4.36s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  15%|â–ˆâ–Œ        | 30/198 [01:26<12:20,  4.41s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  16%|â–ˆâ–Œ        | 31/198 [01:30<12:13,  4.39s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  16%|â–ˆâ–Œ        | 32/198 [01:35<12:25,  4.49s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  17%|â–ˆâ–‹        | 33/198 [01:40<12:15,  4.46s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  17%|â–ˆâ–‹        | 34/198 [01:44<12:13,  4.47s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  18%|â–ˆâ–Š        | 35/198 [01:48<12:06,  4.46s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  18%|â–ˆâ–Š        | 36/198 [01:53<12:17,  4.56s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  19%|â–ˆâ–Š        | 37/198 [01:58<12:07,  4.52s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  19%|â–ˆâ–‰        | 38/198 [02:03<12:18,  4.62s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  20%|â–ˆâ–‰        | 39/198 [02:07<12:25,  4.69s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  20%|â–ˆâ–ˆ        | 40/198 [02:12<12:27,  4.73s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  21%|â–ˆâ–ˆ        | 41/198 [02:17<12:08,  4.64s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  21%|â–ˆâ–ˆ        | 42/198 [02:21<11:44,  4.52s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  22%|â–ˆâ–ˆâ–       | 43/198 [02:23<10:08,  3.92s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  22%|â–ˆâ–ˆâ–       | 44/198 [02:26<08:52,  3.46s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  23%|â–ˆâ–ˆâ–       | 45/198 [02:28<08:08,  3.19s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  23%|â–ˆâ–ˆâ–       | 46/198 [02:31<07:27,  2.95s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  24%|â–ˆâ–ˆâ–       | 47/198 [02:33<07:08,  2.84s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  24%|â–ˆâ–ˆâ–       | 48/198 [02:36<06:49,  2.73s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  25%|â–ˆâ–ˆâ–       | 49/198 [02:38<06:40,  2.69s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  25%|â–ˆâ–ˆâ–Œ       | 50/198 [02:41<06:36,  2.68s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  26%|â–ˆâ–ˆâ–Œ       | 51/198 [02:44<06:28,  2.64s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  26%|â–ˆâ–ˆâ–‹       | 52/198 [02:46<06:15,  2.57s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  27%|â–ˆâ–ˆâ–‹       | 53/198 [02:48<06:10,  2.56s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  27%|â–ˆâ–ˆâ–‹       | 54/198 [02:51<06:00,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  28%|â–ˆâ–ˆâ–Š       | 55/198 [02:54<06:05,  2.55s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  28%|â–ˆâ–ˆâ–Š       | 56/198 [02:56<05:54,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  29%|â–ˆâ–ˆâ–‰       | 57/198 [02:59<05:59,  2.55s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  29%|â–ˆâ–ˆâ–‰       | 58/198 [03:01<05:53,  2.52s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  30%|â–ˆâ–ˆâ–‰       | 59/198 [03:04<05:54,  2.55s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  30%|â–ˆâ–ˆâ–ˆ       | 60/198 [03:06<05:51,  2.54s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  31%|â–ˆâ–ˆâ–ˆ       | 61/198 [03:09<05:50,  2.56s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  31%|â–ˆâ–ˆâ–ˆâ–      | 62/198 [03:11<05:41,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  32%|â–ˆâ–ˆâ–ˆâ–      | 63/198 [03:13<05:24,  2.40s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  32%|â–ˆâ–ˆâ–ˆâ–      | 64/198 [03:16<05:48,  2.60s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  33%|â–ˆâ–ˆâ–ˆâ–      | 65/198 [03:19<06:03,  2.73s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  33%|â–ˆâ–ˆâ–ˆâ–      | 66/198 [03:23<06:15,  2.85s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  34%|â–ˆâ–ˆâ–ˆâ–      | 67/198 [03:26<06:19,  2.90s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  34%|â–ˆâ–ˆâ–ˆâ–      | 68/198 [03:29<06:26,  2.97s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  35%|â–ˆâ–ˆâ–ˆâ–      | 69/198 [03:32<06:25,  2.99s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/198 [03:35<06:26,  3.02s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/198 [03:38<06:22,  3.01s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 72/198 [03:41<06:19,  3.01s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 73/198 [03:44<06:19,  3.04s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/198 [03:47<06:20,  3.07s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/198 [03:50<06:16,  3.06s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/198 [03:53<06:13,  3.06s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 77/198 [03:56<06:10,  3.06s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/198 [03:59<06:08,  3.07s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/198 [04:02<06:03,  3.05s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/198 [04:05<05:59,  3.05s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/198 [04:09<06:11,  3.17s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 82/198 [04:12<06:06,  3.16s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/198 [04:15<05:58,  3.12s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/198 [04:18<05:43,  3.01s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 85/198 [04:20<05:31,  2.93s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 86/198 [04:23<05:19,  2.85s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 87/198 [04:26<05:12,  2.82s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/198 [04:29<05:06,  2.79s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/198 [04:32<05:12,  2.87s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/198 [04:34<05:03,  2.81s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/198 [04:37<04:59,  2.80s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 92/198 [04:40<04:55,  2.79s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/198 [04:43<04:49,  2.76s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/198 [04:45<04:45,  2.74s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/198 [04:48<04:44,  2.76s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/198 [04:51<04:40,  2.75s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 97/198 [04:54<04:38,  2.75s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/198 [04:56<04:34,  2.75s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 99/198 [04:59<04:32,  2.75s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/198 [05:02<04:26,  2.72s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/198 [05:04<04:23,  2.72s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 102/198 [05:07<04:23,  2.75s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/198 [05:10<04:29,  2.83s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/198 [05:13<04:18,  2.75s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 105/198 [05:15<04:10,  2.70s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 106/198 [05:19<04:40,  3.04s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 107/198 [05:23<04:59,  3.29s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/198 [05:27<05:13,  3.48s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 109/198 [05:31<05:19,  3.59s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/198 [05:35<05:23,  3.68s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/198 [05:39<05:25,  3.74s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 112/198 [05:43<05:27,  3.80s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/198 [05:47<05:28,  3.87s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 114/198 [05:50<05:24,  3.86s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/198 [05:54<05:23,  3.89s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/198 [05:58<05:23,  3.94s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 117/198 [06:02<05:14,  3.88s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/198 [06:06<05:13,  3.91s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 119/198 [06:10<05:08,  3.91s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/198 [06:14<05:07,  3.94s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/198 [06:18<05:01,  3.91s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 122/198 [06:22<04:54,  3.87s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/198 [06:26<04:50,  3.87s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/198 [06:30<04:49,  3.91s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 125/198 [06:33<04:42,  3.87s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 126/198 [06:37<04:30,  3.75s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 127/198 [06:40<04:23,  3.71s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/198 [06:44<04:25,  3.80s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 129/198 [06:48<04:21,  3.79s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/198 [06:52<04:17,  3.79s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/198 [06:56<04:07,  3.70s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 132/198 [06:59<04:05,  3.73s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/198 [07:03<04:02,  3.72s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 134/198 [07:07<03:57,  3.70s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/198 [07:11<03:55,  3.74s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/198 [07:14<03:54,  3.78s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 137/198 [07:18<03:50,  3.79s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/198 [07:22<03:49,  3.83s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 139/198 [07:26<03:42,  3.78s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/198 [07:30<03:38,  3.78s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/198 [07:33<03:32,  3.74s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 142/198 [07:37<03:29,  3.75s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/198 [07:41<03:24,  3.72s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/198 [07:44<03:21,  3.73s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 145/198 [07:48<03:17,  3.74s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 146/198 [07:52<03:16,  3.79s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 147/198 [07:56<03:08,  3.69s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/198 [07:59<03:06,  3.74s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 149/198 [08:03<02:57,  3.63s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/198 [08:06<02:51,  3.58s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 151/198 [08:09<02:33,  3.27s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 152/198 [08:11<02:22,  3.10s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/198 [08:14<02:12,  2.95s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 154/198 [08:17<02:06,  2.86s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/198 [08:19<02:00,  2.80s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 156/198 [08:22<01:57,  2.79s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 157/198 [08:25<01:52,  2.73s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/198 [08:27<01:48,  2.72s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 159/198 [08:30<01:44,  2.68s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/198 [08:33<01:41,  2.67s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 161/198 [08:35<01:37,  2.65s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 162/198 [08:38<01:34,  2.63s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/198 [08:40<01:31,  2.62s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/198 [08:43<01:28,  2.61s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 165/198 [08:46<01:25,  2.61s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 166/198 [08:48<01:23,  2.61s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 167/198 [08:51<01:20,  2.58s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/198 [08:53<01:18,  2.62s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 169/198 [08:56<01:15,  2.62s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/198 [08:59<01:12,  2.60s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 171/198 [09:01<01:09,  2.59s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 172/198 [09:04<01:07,  2.59s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/198 [09:06<01:04,  2.58s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 174/198 [09:09<01:01,  2.56s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/198 [09:11<00:57,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 176/198 [09:14<00:55,  2.54s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 177/198 [09:16<00:52,  2.49s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/198 [09:19<00:50,  2.52s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 179/198 [09:21<00:48,  2.54s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/198 [09:24<00:46,  2.56s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 181/198 [09:27<00:43,  2.56s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 182/198 [09:29<00:41,  2.59s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/198 [09:32<00:38,  2.59s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/198 [09:35<00:36,  2.62s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 185/198 [09:37<00:33,  2.61s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 186/198 [09:40<00:31,  2.64s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 187/198 [09:42<00:28,  2.63s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/198 [09:45<00:25,  2.60s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 189/198 [09:47<00:23,  2.56s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/198 [09:50<00:20,  2.58s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 191/198 [09:53<00:18,  2.58s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 192/198 [09:55<00:15,  2.58s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/198 [09:58<00:12,  2.58s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 194/198 [10:00<00:10,  2.53s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/198 [10:03<00:07,  2.49s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 196/198 [10:05<00:05,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 197/198 [10:08<00:02,  2.48s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198/198 [10:10<00:00,  3.08s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"print(\"ES test:\", predictions_es)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:53:44.898426Z","iopub.execute_input":"2025-12-23T18:53:44.898668Z","iopub.status.idle":"2025-12-23T18:53:44.902642Z","shell.execute_reply.started":"2025-12-23T18:53:44.898642Z","shell.execute_reply":"2025-12-23T18:53:44.902028Z"}},"outputs":[{"name":"stdout","text":"ES test: [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"cantidad_none = predictions_es.count(None)\ntotal_es = len(predictions_es)\nporcentaje_es = cantidad_none / total_es\n\nprint(f\"Cantidad de valores None: {cantidad_none}, Total de predicciones: {total_es}\")\nprint(f\"Porcentaje de Nones: {porcentaje_es:.2%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:53:44.903426Z","iopub.execute_input":"2025-12-23T18:53:44.903659Z","iopub.status.idle":"2025-12-23T18:53:44.916672Z","shell.execute_reply.started":"2025-12-23T18:53:44.903636Z","shell.execute_reply":"2025-12-23T18:53:44.916002Z"}},"outputs":[{"name":"stdout","text":"Cantidad de valores None: 0, Total de predicciones: 198\nPorcentaje de Nones: 0.00%\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"## **QUITO LOS NONE**","metadata":{}},{"cell_type":"code","source":"filtrados = [(h, p) for h, p in zip(referencias_es, predictions_es) if h is not None and p is not None]\nhum_limpio, predictions_limpio = zip(*filtrados)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:53:44.917583Z","iopub.execute_input":"2025-12-23T18:53:44.917979Z","iopub.status.idle":"2025-12-23T18:53:44.929394Z","shell.execute_reply.started":"2025-12-23T18:53:44.917922Z","shell.execute_reply":"2025-12-23T18:53:44.928656Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"print(hum_limpio)\nprint(predictions_limpio)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:53:44.930464Z","iopub.execute_input":"2025-12-23T18:53:44.930829Z","iopub.status.idle":"2025-12-23T18:53:44.940609Z","shell.execute_reply.started":"2025-12-23T18:53:44.930791Z","shell.execute_reply":"2025-12-23T18:53:44.939870Z"}},"outputs":[{"name":"stdout","text":"(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 5, 3, 4, 4, 4, 4, 5, 3, 4, 5, 5, 4, 4, 5, 4, 4, 5, 5, 4, 3, 4, 5, 5, 5, 5, 4, 5, 5, 4, 5, 4, 4, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 2, 4, 3, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 5, 5, 4, 5, 4, 5, 5, 4)\n(5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0)\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"## **MÃ‰TRICAS**","metadata":{}},{"cell_type":"markdown","source":"## **SPEARMANR**","metadata":{}},{"cell_type":"code","source":"# Mide si el modelo puede ordenar los modelos de peor a mejor \n# en comparaciÃ³n con las puntuaciones humanas (no exactamente la misma puntuaciÃ³n)\ns, p = spearmanr(hum_limpio, predictions_limpio)\nprint(f\"Spearman ES: {s:.3f}, p-value: {p:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:53:44.941460Z","iopub.execute_input":"2025-12-23T18:53:44.941759Z","iopub.status.idle":"2025-12-23T18:53:44.952474Z","shell.execute_reply.started":"2025-12-23T18:53:44.941735Z","shell.execute_reply":"2025-12-23T18:53:44.951759Z"}},"outputs":[{"name":"stdout","text":"Spearman ES: nan, p-value: nan\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/2794225215.py:3: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  s, p = spearmanr(hum_limpio, predictions_limpio)\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## **KENDALLTAU**","metadata":{}},{"cell_type":"code","source":"# Mide la capacidad para ordenar los resumenes segÃºn su calidad, \n# pero se calcula por parejas (de estos dos cuÃ¡l es el mejor?)\ntau, p_value = scipy.stats.kendalltau(hum_limpio, predictions_limpio)\nprint(f\"Kendalltau ES: {tau:.3f}, p-value: {p_value:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:53:44.953333Z","iopub.execute_input":"2025-12-23T18:53:44.953608Z","iopub.status.idle":"2025-12-23T18:53:44.972007Z","shell.execute_reply.started":"2025-12-23T18:53:44.953574Z","shell.execute_reply":"2025-12-23T18:53:44.971454Z"}},"outputs":[{"name":"stdout","text":"Kendalltau ES: nan, p-value: nan\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"## **MAE**","metadata":{}},{"cell_type":"code","source":"# Error medio absoluto\n# Mide la distancia media entre las puntuaciones predichas por los modelos \n# y las dadas por los humanos\n# Es decir, menos de 0,5 (ej.: humano -> 5, modelo -> 4.60)\nmae = np.mean(np.abs(np.array(hum_limpio) - np.array(predictions_limpio)))\nprint(f\"MAE ES: {mae}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:53:44.972695Z","iopub.execute_input":"2025-12-23T18:53:44.972986Z","iopub.status.idle":"2025-12-23T18:53:44.976707Z","shell.execute_reply.started":"2025-12-23T18:53:44.972932Z","shell.execute_reply":"2025-12-23T18:53:44.976208Z"}},"outputs":[{"name":"stdout","text":"MAE ES: 0.3181818181818182\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"# **TEST GL**","metadata":{}},{"cell_type":"code","source":"predictions_gl = evaluate_metric_model(model, test_gl_dataset,  tokenizer, \"Consistency\")\nprint(\"GL test:\", predictions_gl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:53:44.977643Z","iopub.execute_input":"2025-12-23T18:53:44.978002Z","iopub.status.idle":"2025-12-23T18:59:53.758250Z","shell.execute_reply.started":"2025-12-23T18:53:44.977934Z","shell.execute_reply":"2025-12-23T18:59:53.757415Z"}},"outputs":[{"name":"stderr","text":"Evaluating Consistency model:   1%|          | 1/150 [00:01<04:25,  1.78s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   1%|â–         | 2/150 [00:03<04:21,  1.77s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   2%|â–         | 3/150 [00:05<04:17,  1.75s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   3%|â–         | 4/150 [00:07<04:17,  1.76s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   3%|â–         | 5/150 [00:08<04:15,  1.76s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   4%|â–         | 6/150 [00:10<04:14,  1.77s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   5%|â–         | 7/150 [00:12<04:06,  1.73s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   5%|â–Œ         | 8/150 [00:13<04:06,  1.73s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   6%|â–Œ         | 9/150 [00:15<03:57,  1.68s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   7%|â–‹         | 10/150 [00:17<03:50,  1.64s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   7%|â–‹         | 11/150 [00:20<05:07,  2.21s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   8%|â–Š         | 12/150 [00:24<05:58,  2.60s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   9%|â–Š         | 13/150 [00:27<06:15,  2.74s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:   9%|â–‰         | 14/150 [00:30<06:29,  2.86s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  10%|â–ˆ         | 15/150 [00:33<06:34,  2.92s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  11%|â–ˆ         | 16/150 [00:36<06:37,  2.97s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  11%|â–ˆâ–        | 17/150 [00:39<06:28,  2.92s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  12%|â–ˆâ–        | 18/150 [00:42<06:30,  2.96s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  13%|â–ˆâ–        | 19/150 [00:45<06:31,  2.99s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  13%|â–ˆâ–        | 20/150 [00:48<06:28,  2.99s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  14%|â–ˆâ–        | 21/150 [00:50<06:01,  2.80s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  15%|â–ˆâ–        | 22/150 [00:53<05:42,  2.67s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  15%|â–ˆâ–Œ        | 23/150 [00:55<05:17,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  16%|â–ˆâ–Œ        | 24/150 [00:57<04:59,  2.38s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  17%|â–ˆâ–‹        | 25/150 [00:59<04:46,  2.29s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  17%|â–ˆâ–‹        | 26/150 [01:01<04:37,  2.24s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  18%|â–ˆâ–Š        | 27/150 [01:03<04:29,  2.19s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  19%|â–ˆâ–Š        | 28/150 [01:05<04:33,  2.24s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  19%|â–ˆâ–‰        | 29/150 [01:07<04:18,  2.13s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  20%|â–ˆâ–ˆ        | 30/150 [01:09<04:06,  2.06s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  21%|â–ˆâ–ˆ        | 31/150 [01:11<04:04,  2.06s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  21%|â–ˆâ–ˆâ–       | 32/150 [01:13<04:04,  2.07s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  22%|â–ˆâ–ˆâ–       | 33/150 [01:15<03:56,  2.02s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  23%|â–ˆâ–ˆâ–       | 34/150 [01:17<03:57,  2.05s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  23%|â–ˆâ–ˆâ–       | 35/150 [01:19<03:55,  2.05s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  24%|â–ˆâ–ˆâ–       | 36/150 [01:21<03:54,  2.06s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  25%|â–ˆâ–ˆâ–       | 37/150 [01:23<03:42,  1.97s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  25%|â–ˆâ–ˆâ–Œ       | 38/150 [01:25<03:36,  1.93s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  26%|â–ˆâ–ˆâ–Œ       | 39/150 [01:27<03:28,  1.88s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  27%|â–ˆâ–ˆâ–‹       | 40/150 [01:29<03:25,  1.87s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  27%|â–ˆâ–ˆâ–‹       | 41/150 [01:31<03:47,  2.09s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  28%|â–ˆâ–ˆâ–Š       | 42/150 [01:34<04:00,  2.22s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  29%|â–ˆâ–ˆâ–Š       | 43/150 [01:36<04:03,  2.28s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  29%|â–ˆâ–ˆâ–‰       | 44/150 [01:39<04:10,  2.37s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  30%|â–ˆâ–ˆâ–ˆ       | 45/150 [01:41<04:13,  2.42s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  31%|â–ˆâ–ˆâ–ˆ       | 46/150 [01:44<04:16,  2.46s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  31%|â–ˆâ–ˆâ–ˆâ–      | 47/150 [01:46<04:10,  2.43s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  32%|â–ˆâ–ˆâ–ˆâ–      | 48/150 [01:49<04:06,  2.42s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  33%|â–ˆâ–ˆâ–ˆâ–      | 49/150 [01:51<04:01,  2.39s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  33%|â–ˆâ–ˆâ–ˆâ–      | 50/150 [01:53<03:58,  2.38s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  34%|â–ˆâ–ˆâ–ˆâ–      | 51/150 [02:02<06:57,  4.22s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n\n[ORIGINAL DOCUMENT] This is the original document on which the summary is based.\n    O pasado xoves presentouse en Lugo presentouse a plata\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  35%|â–ˆâ–ˆâ–ˆâ–      | 52/150 [02:10<09:00,  5.52s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n\n[ORIGINAL DOCUMENT] This is the original document on which the summary is based.\n    O pasado xoves presentouse en Lugo a plataforma\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 53/150 [02:19<10:15,  6.34s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n\n[ORIGINAL DOCUMENT] This is the original document on which the summary is based.\n    O pasado xoves presentouse en Lugo a plataforma\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 54/150 [02:23<09:21,  5.85s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 55/150 [02:28<08:42,  5.51s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 56/150 [02:33<08:13,  5.25s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 57/150 [02:37<07:44,  5.00s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 58/150 [02:42<07:26,  4.85s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 59/150 [02:46<07:07,  4.70s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 60/150 [02:50<06:53,  4.60s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 61/150 [02:53<06:07,  4.13s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 62/150 [02:56<05:34,  3.80s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 63/150 [02:59<04:57,  3.42s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 64/150 [03:02<04:37,  3.22s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 65/150 [03:04<04:19,  3.06s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/150 [03:07<04:08,  2.96s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 67/150 [03:10<03:56,  2.85s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 68/150 [03:12<03:50,  2.81s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 69/150 [03:15<03:41,  2.74s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 70/150 [03:18<03:35,  2.70s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 71/150 [03:19<03:12,  2.44s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 72/150 [03:21<03:00,  2.32s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 73/150 [03:23<02:45,  2.14s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 74/150 [03:25<02:37,  2.07s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 75/150 [03:27<02:31,  2.02s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 76/150 [03:29<02:26,  1.98s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 77/150 [03:31<02:18,  1.90s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 78/150 [03:32<02:14,  1.86s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 79/150 [03:34<02:09,  1.82s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 80/150 [03:36<02:05,  1.80s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 81/150 [03:38<02:03,  1.79s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/150 [03:39<02:01,  1.78s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 83/150 [03:41<01:56,  1.74s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 84/150 [03:43<01:55,  1.75s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 85/150 [03:45<01:53,  1.75s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 86/150 [03:46<01:53,  1.78s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 87/150 [03:48<01:50,  1.76s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 88/150 [03:50<01:46,  1.72s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 89/150 [03:51<01:42,  1.69s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 90/150 [03:53<01:38,  1.64s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 91/150 [03:56<01:54,  1.95s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 92/150 [03:58<02:03,  2.12s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 93/150 [04:01<02:07,  2.24s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 94/150 [04:03<02:10,  2.33s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 95/150 [04:06<02:12,  2.41s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 96/150 [04:08<02:12,  2.46s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 97/150 [04:12<02:26,  2.76s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 98/150 [04:14<02:20,  2.70s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 99/150 [04:17<02:12,  2.60s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 100/150 [04:19<02:05,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 101/150 [04:21<01:56,  2.38s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 102/150 [04:23<01:52,  2.34s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 103/150 [04:25<01:43,  2.20s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 104/150 [04:27<01:40,  2.18s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 105/150 [04:29<01:36,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 106/150 [04:31<01:33,  2.13s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 107/150 [04:34<01:31,  2.12s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 108/150 [04:35<01:26,  2.05s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 109/150 [04:37<01:22,  2.00s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 110/150 [04:39<01:17,  1.94s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 111/150 [04:42<01:23,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 112/150 [04:45<01:28,  2.33s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 113/150 [04:47<01:29,  2.41s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 114/150 [04:50<01:29,  2.48s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 115/150 [04:52<01:27,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 116/150 [04:55<01:26,  2.53s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 117/150 [04:57<01:23,  2.53s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 118/150 [05:00<01:21,  2.55s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 119/150 [05:03<01:19,  2.56s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 120/150 [05:05<01:16,  2.55s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 121/150 [05:07<01:07,  2.31s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 122/150 [05:09<01:00,  2.17s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 123/150 [05:10<00:54,  2.01s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 124/150 [05:12<00:48,  1.88s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 125/150 [05:14<00:46,  1.85s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 126/150 [05:15<00:43,  1.81s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 127/150 [05:17<00:40,  1.76s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 128/150 [05:19<00:38,  1.76s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 129/150 [05:20<00:35,  1.70s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 130/150 [05:22<00:33,  1.65s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 131/150 [05:25<00:39,  2.06s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 132/150 [05:28<00:43,  2.39s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 133/150 [05:31<00:44,  2.59s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 134/150 [05:34<00:43,  2.73s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 135/150 [05:37<00:42,  2.83s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 136/150 [05:40<00:40,  2.90s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 137/150 [05:43<00:38,  2.94s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 138/150 [05:46<00:35,  2.97s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 139/150 [05:49<00:32,  2.91s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 140/150 [05:52<00:28,  2.86s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 141/150 [05:54<00:22,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 142/150 [05:55<00:18,  2.27s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 143/150 [05:57<00:14,  2.06s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 144/150 [05:59<00:11,  1.96s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 145/150 [06:00<00:09,  1.89s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 146/150 [06:02<00:07,  1.86s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 147/150 [06:04<00:05,  1.76s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 148/150 [06:05<00:03,  1.70s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 149/150 [06:07<00:01,  1.65s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Consistency model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [06:08<00:00,  2.46s/it]","output_type":"stream"},{"name":"stdout","text":"[CONSISTENCY]: 5\nGL test: [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"cantidad_none_gl = predictions_gl.count(None)\ntotal_gl = len(predictions_gl)\nporcentaje_gl = cantidad_none_gl / total_gl\n\nprint(f\"Cantidad de valores None: {cantidad_none_gl}, Total de predicciones: {total_gl}\")\nprint(f\"Porcentaje de Nones: {porcentaje_gl:.2%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:59:53.759293Z","iopub.execute_input":"2025-12-23T18:59:53.759586Z","iopub.status.idle":"2025-12-23T18:59:53.764301Z","shell.execute_reply.started":"2025-12-23T18:59:53.759552Z","shell.execute_reply":"2025-12-23T18:59:53.763643Z"}},"outputs":[{"name":"stdout","text":"Cantidad de valores None: 0, Total de predicciones: 150\nPorcentaje de Nones: 0.00%\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"## **QUITO LOS NONE**","metadata":{}},{"cell_type":"code","source":"filtrados_gl = [(h, p) for h, p in zip(referencias_gl, predictions_gl) if h is not None and p is not None]\nhum_limpio_gl, predictions_limpio_gl = zip(*filtrados_gl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:59:53.765066Z","iopub.execute_input":"2025-12-23T18:59:53.765812Z","iopub.status.idle":"2025-12-23T18:59:53.776592Z","shell.execute_reply.started":"2025-12-23T18:59:53.765773Z","shell.execute_reply":"2025-12-23T18:59:53.775760Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"print(hum_limpio_gl)\nprint(predictions_limpio_gl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:59:53.777466Z","iopub.execute_input":"2025-12-23T18:59:53.777773Z","iopub.status.idle":"2025-12-23T18:59:53.786786Z","shell.execute_reply.started":"2025-12-23T18:59:53.777739Z","shell.execute_reply":"2025-12-23T18:59:53.786200Z"}},"outputs":[{"name":"stdout","text":"(5, 4, 5, 2, 4, 4, 5, 5, 5, 3, 4, 4, 3, 3, 3, 4, 5, 4, 4, 5, 5, 5, 5, 2, 2, 2, 5, 5, 5, 4, 5, 4, 5, 3, 4, 5, 5, 4, 5, 5, 5, 5, 5, 3, 4, 4, 5, 5, 5, 5, 5, 5, 4, 4, 2, 3, 5, 5, 5, 5, 4, 5, 5, 2, 1, 4, 5, 5, 5, 5, 5, 5, 5, 2, 3, 2, 5, 5, 5, 5, 4, 4, 5, 2, 3, 4, 5, 5, 5, 5, 4, 4, 5, 1, 3, 4, 5, 5, 5, 5, 5, 5, 5, 1, 2, 2, 5, 5, 5, 5, 5, 5, 4, 1, 4, 4, 5, 5, 5, 1, 5, 5, 5, 1, 4, 1, 5, 5, 5, 5, 5, 4, 5, 1, 2, 4, 5, 5, 5, 5, 5, 4, 5, 2, 4, 3, 5, 4, 4, 5)\n(5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0)\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"## **MÃ‰TRICAS**","metadata":{}},{"cell_type":"markdown","source":"## **SPEARMANR**","metadata":{}},{"cell_type":"code","source":"# Mide si el modelo puede ordenar los modelos de peor a mejor \n# en comparaciÃ³n con las puntuaciones humanas (no exactamente la misma puntuaciÃ³n)\ns, p = spearmanr(hum_limpio_gl, predictions_limpio_gl)\nprint(f\"Spearman GL: {s:.3f}, p-value: {p:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:59:53.787666Z","iopub.execute_input":"2025-12-23T18:59:53.787916Z","iopub.status.idle":"2025-12-23T18:59:53.798433Z","shell.execute_reply.started":"2025-12-23T18:59:53.787893Z","shell.execute_reply":"2025-12-23T18:59:53.797632Z"}},"outputs":[{"name":"stdout","text":"Spearman GL: nan, p-value: nan\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/1383017292.py:3: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  s, p = spearmanr(hum_limpio_gl, predictions_limpio_gl)\n","output_type":"stream"}],"execution_count":55},{"cell_type":"markdown","source":"## **KENDALLTAU**","metadata":{}},{"cell_type":"code","source":"# Mide la capacidad para ordenar los resumenes segÃºn su calidad, \n# pero se calcula por parejas (de estos dos cuÃ¡l es el mejor?)\ntau, p_value = scipy.stats.kendalltau(hum_limpio_gl, predictions_limpio_gl)\nprint(f\"Kendalltau GL: {tau:.3f}, p-value: {p_value:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:59:53.799366Z","iopub.execute_input":"2025-12-23T18:59:53.799869Z","iopub.status.idle":"2025-12-23T18:59:53.808568Z","shell.execute_reply.started":"2025-12-23T18:59:53.799835Z","shell.execute_reply":"2025-12-23T18:59:53.808019Z"}},"outputs":[{"name":"stdout","text":"Kendalltau GL: nan, p-value: nan\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"## **MAE**","metadata":{}},{"cell_type":"code","source":"# Error medio absoluto\n# Mide la distancia media entre las puntuaciones predichas por los modelos \n# y las dadas por los humanos\n# Es decir, menos de 0,5 (ej.: humano -> 5, modelo -> 4.60)\nmae = np.mean(np.abs(np.array(hum_limpio_gl) - np.array(predictions_limpio_gl)))\nprint(f\"MAE GL: {mae}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:59:53.809413Z","iopub.execute_input":"2025-12-23T18:59:53.810053Z","iopub.status.idle":"2025-12-23T18:59:53.820091Z","shell.execute_reply.started":"2025-12-23T18:59:53.810026Z","shell.execute_reply":"2025-12-23T18:59:53.819424Z"}},"outputs":[{"name":"stdout","text":"MAE GL: 0.8466666666666667\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}