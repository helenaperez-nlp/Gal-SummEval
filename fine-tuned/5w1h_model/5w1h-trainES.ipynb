{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13970127,"sourceType":"datasetVersion","datasetId":8906005},{"sourceId":14191599,"sourceType":"datasetVersion","datasetId":9049029},{"sourceId":14191605,"sourceType":"datasetVersion","datasetId":9049035}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"WANDB_MODE\"] = \"disabled\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:26:49.524939Z","iopub.execute_input":"2025-12-29T15:26:49.525470Z","iopub.status.idle":"2025-12-29T15:26:49.529104Z","shell.execute_reply.started":"2025-12-29T15:26:49.525442Z","shell.execute_reply":"2025-12-29T15:26:49.528444Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Try to avoid OOM error when training the model\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:26:49.533062Z","iopub.execute_input":"2025-12-29T15:26:49.533684Z","iopub.status.idle":"2025-12-29T15:26:49.543785Z","shell.execute_reply.started":"2025-12-29T15:26:49.533650Z","shell.execute_reply":"2025-12-29T15:26:49.543201Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!pip install --upgrade unsloth peft bitsandbytes accelerate trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:26:49.545197Z","iopub.execute_input":"2025-12-29T15:26:49.545684Z","iopub.status.idle":"2025-12-29T15:29:32.803190Z","shell.execute_reply.started":"2025-12-29T15:26:49.545661Z","shell.execute_reply":"2025-12-29T15:29:32.802465Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.12.9-py3-none-any.whl.metadata (65 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\nCollecting peft\n  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nCollecting accelerate\n  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\nCollecting trl\n  Downloading trl-0.26.2-py3-none-any.whl.metadata (11 kB)\nCollecting unsloth_zoo>=2025.12.7 (from unsloth)\n  Downloading unsloth_zoo-2025.12.7-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.8.0+cu126)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.23.0+cu126)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\nCollecting tyro (from unsloth)\n  Downloading tyro-1.0.3-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.4.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\nCollecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth)\n  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.2)\nRequirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.57.1)\nCollecting trl\n  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.3)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.20.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\nCollecting multiprocess<0.70.17 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\nCollecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (0.22.1)\nCollecting torchao>=0.13.0 (from unsloth_zoo>=2025.12.7->unsloth)\n  Downloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.12.7->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.7->unsloth) (11.3.0)\nCollecting msgspec (from unsloth_zoo>=2025.12.7->unsloth)\n  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.10.2.21->torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.1.2->torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nccl-cu12==2.27.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.0.4->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (0.17.0)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\nDownloading unsloth-2025.12.9-py3-none-any.whl (376 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.18.0-py3-none-any.whl (556 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.12.7-py3-none-any.whl (290 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m290.7/290.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-1.0.3-py3-none-any.whl (180 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torchao, triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multiprocess, msgspec, fsspec, tyro, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, accelerate, trl, peft, unsloth_zoo, unsloth\n  Attempting uninstall: torchao\n    Found existing installation: torchao 0.10.0\n    Uninstalling torchao-0.10.0:\n      Successfully uninstalled torchao-0.10.0\n  Attempting uninstall: triton\n    Found existing installation: triton 3.4.0\n    Uninstalling triton-3.4.0:\n      Successfully uninstalled triton-3.4.0\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.6.77\n    Uninstalling nvidia-nvtx-cu12-12.6.77:\n      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n  Attempting uninstall: nvidia-nvshmem-cu12\n    Found existing installation: nvidia-nvshmem-cu12 3.4.5\n    Uninstalling nvidia-nvshmem-cu12-3.4.5:\n      Successfully uninstalled nvidia-nvshmem-cu12-3.4.5\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.27.3\n    Uninstalling nvidia-nccl-cu12-2.27.3:\n      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufile-cu12\n    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.18\n    Uninstalling multiprocess-0.70.18:\n      Successfully uninstalled multiprocess-0.70.18\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.10.0\n    Uninstalling fsspec-2025.10.0:\n      Successfully uninstalled fsspec-2025.10.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.8.0+cu126\n    Uninstalling torch-2.8.0+cu126:\n      Successfully uninstalled torch-2.8.0+cu126\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.4.1\n    Uninstalling datasets-4.4.1:\n      Successfully uninstalled datasets-4.4.1\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.23.0+cu126\n    Uninstalling torchvision-0.23.0+cu126:\n      Successfully uninstalled torchvision-0.23.0+cu126\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.11.0\n    Uninstalling accelerate-1.11.0:\n      Successfully uninstalled accelerate-1.11.0\n  Attempting uninstall: peft\n    Found existing installation: peft 0.17.1\n    Uninstalling peft-0.17.1:\n      Successfully uninstalled peft-0.17.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nfastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.1 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\ntorchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-1.12.0 bitsandbytes-0.49.0 cut_cross_entropy-25.1.1 datasets-4.3.0 fsspec-2025.9.0 msgspec-0.20.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 peft-0.18.0 torch-2.9.1 torchao-0.15.0 torchvision-0.24.1 triton-3.5.1 trl-0.24.0 tyro-1.0.3 unsloth-2025.12.9 unsloth_zoo-2025.12.7 xformers-0.0.33.post2\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:29:32.804958Z","iopub.execute_input":"2025-12-29T15:29:32.805187Z","iopub.status.idle":"2025-12-29T15:29:39.244613Z","shell.execute_reply.started":"2025-12-29T15:29:32.805161Z","shell.execute_reply":"2025-12-29T15:29:39.243724Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\nRequirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.6\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# **IMPORTS**","metadata":{}},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:29:39.246147Z","iopub.execute_input":"2025-12-29T15:29:39.247019Z","iopub.status.idle":"2025-12-29T15:30:14.160389Z","shell.execute_reply.started":"2025-12-29T15:29:39.246973Z","shell.execute_reply":"2025-12-29T15:30:14.159823Z"}},"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-12-29 15:29:46.513149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767022186.690979      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767022186.741343      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767022187.161308      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767022187.161347      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767022187.161350      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767022187.161352      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import scipy\nimport json\nimport re\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nimport evaluate\nfrom scipy.stats import spearmanr, kendalltau\nfrom datasets import Dataset\nfrom tqdm import tqdm\nimport glob\n\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling, EarlyStoppingCallback\nfrom peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training, PeftModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:30:14.161923Z","iopub.execute_input":"2025-12-29T15:30:14.162618Z","iopub.status.idle":"2025-12-29T15:30:14.341641Z","shell.execute_reply.started":"2025-12-29T15:30:14.162585Z","shell.execute_reply":"2025-12-29T15:30:14.341102Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# **CARGO LOS DATOS**","metadata":{}},{"cell_type":"code","source":"def load_jsonl(path):\n    data = []\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                data.append(json.loads(line))\n        return pd.DataFrame(data)\n    except FileNotFoundError:\n        print(f\"Error: No se encontrÃ³ el archivo {path}\")\n        return pd.DataFrame()\n\ndf_es = load_jsonl(\"/kaggle/input/basse-es-jsonl/BASSE_es.jsonl\")\n#df_eu = load_jsonl(\"/kaggle/input/basse-eu-jsonl/BASSE_eu.jsonl\")\ndf_test_gl = load_jsonl(\"/kaggle/input/basse-gl-jsonl/BASSE.gl.jsonl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:30:14.342398Z","iopub.execute_input":"2025-12-29T15:30:14.342684Z","iopub.status.idle":"2025-12-29T15:30:14.397003Z","shell.execute_reply.started":"2025-12-29T15:30:14.342658Z","shell.execute_reply":"2025-12-29T15:30:14.396460Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# **DIVIDO EL CONJUNTO DE DATOS**","metadata":{}},{"cell_type":"code","source":"# 1 -> Separamos test sets para ES (10%)\n#train_dev_es, test_es = train_test_split(df_es, test_size=0.1, random_state=42, shuffle=True)\ntrain_dev_es, test_es = train_test_split(df_es, test_size=0.2, random_state=42, shuffle=True)\n# 2 -> Creamos train sets (80% total) y dev sets (10% total) para ES y EU\n#train_es, dev_es = train_test_split(train_dev_es, test_size=0.1111, random_state=42, shuffle=True)\ntrain_es, dev_es = train_test_split(train_dev_es, test_size=8/36, random_state=42, shuffle=True)\n\n# 3 -> Ajustamos el tamaÃ±o del train set (train_set_length ==> modeloES = modeloEU = modeloES-EU)\n#train_es_fewshot = train_es.head(20)\n#train_eu_fewshot = train_eu.head(20)\n\n# 4 -> Shuffle ES + EU\ndf_train = train_es\ndf_dev = dev_es\n\n# 5 -> Ponemos nombres claros a los test\ndf_test_es = test_es.reset_index(drop=True)\n# df_test_gl \n\nprint(f\"TRAIN:    {len(df_train)}\")\nprint(f\"DEV:      {len(df_dev)}\")\nprint(\"-\" * 30)\nprint(f\"TEST ES:  {len(df_test_es)}\")\nprint(f\"TEST GL:  {len(df_test_gl)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:30:14.397906Z","iopub.execute_input":"2025-12-29T15:30:14.398170Z","iopub.status.idle":"2025-12-29T15:30:14.416534Z","shell.execute_reply.started":"2025-12-29T15:30:14.398143Z","shell.execute_reply":"2025-12-29T15:30:14.415995Z"}},"outputs":[{"name":"stdout","text":"TRAIN:    28\nDEV:      8\n------------------------------\nTEST ES:  9\nTEST GL:  15\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# **COMO UN RESUMEN TIENE MAS DE UNA ANOTACIÃ“N, HAGO LA MEDIA**","metadata":{}},{"cell_type":"code","source":"def extraer_resumenes(df):\n    res = []\n\n    for _, row in df.iterrows():\n        original = row.get('original_document', '')\n        \n        model_data = row.get('model_summaries', {})\n        \n        if isinstance(model_data, dict):\n            for model_name, contenido in model_data.items():\n                summary = contenido.get(\"summ\", None)\n                anns = contenido.get(\"anns\", {})\n                \n                w1h_vals = anns.get(\"5W1H\", None)\n\n                if summary and w1h_vals:\n                    if isinstance(w1h_vals, list):\n                        score = np.mean(w1h_vals)\n                    else:\n                        score = float(w1h_vals)\n                        \n                    media = int(round(score))\n                    \n                    res.append((summary, media, original))\n\n    return pd.DataFrame(res, columns=[\"summary\", \"5W1H\", \"original_document\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:30:14.417459Z","iopub.execute_input":"2025-12-29T15:30:14.417745Z","iopub.status.idle":"2025-12-29T15:30:14.429456Z","shell.execute_reply.started":"2025-12-29T15:30:14.417720Z","shell.execute_reply":"2025-12-29T15:30:14.428870Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df_train_redondeo = extraer_resumenes(df_train)\ndf_dev_redondeo = extraer_resumenes(df_dev)\ndf_test_es_redondeo = extraer_resumenes(df_test_es)\ndf_test_gl_redondeo = extraer_resumenes(df_test_gl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:30:14.430345Z","iopub.execute_input":"2025-12-29T15:30:14.430627Z","iopub.status.idle":"2025-12-29T15:30:14.464507Z","shell.execute_reply.started":"2025-12-29T15:30:14.430584Z","shell.execute_reply":"2025-12-29T15:30:14.463778Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(f\"Ejemplos procesados TRAIN: {len(df_train_redondeo)}\")\nprint(f\"Ejemplos procesados DEV: {len(df_dev_redondeo)}\")\nprint(f\"Ejemplos procesados TEST es: {len(df_test_es_redondeo)}\")\nprint(f\"Ejemplos procesados TEST gl: {len(df_test_gl_redondeo)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:30:14.465515Z","iopub.execute_input":"2025-12-29T15:30:14.465915Z","iopub.status.idle":"2025-12-29T15:30:14.479055Z","shell.execute_reply.started":"2025-12-29T15:30:14.465874Z","shell.execute_reply":"2025-12-29T15:30:14.478278Z"}},"outputs":[{"name":"stdout","text":"Ejemplos procesados TRAIN: 624\nEjemplos procesados DEV: 168\nEjemplos procesados TEST es: 198\nEjemplos procesados TEST gl: 150\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# **CONSTRUYO EL PROMPT**","metadata":{}},{"cell_type":"code","source":"def construct_metric_prompt_simple(row, target_metric):\n    \"\"\"Construye un prompt de instrucciÃ³n para evaluar un resumen usando una mÃ©trica especÃ­fica\"\"\"\n    \n    summary = row['summary']\n    original_document = row['original_document']\n\n    score = row[target_metric]\n    \n    prompt = f\"\"\"[INSTRUCCIÃ“N]\nAs an expert evaluator, analyze the following summary.\nEvaluate solely the {target_metric} criterion on a scale of 1 to 5, where 1 is the lowest score and 5 is the highest.\n\nCriterion: 5W1H: maintenance of all important information (the Ws in 5W1H - who, what, when, where, why, how) from the source document. \nThe summary should not lack any important information available in the source\n\n The summary does not contain any ideas from the original text.\n The summary contains a large amount of incorrect information.\n The summary contains several incorrect pieces of information.\n The summary contains once incorrect piece of information.\t\n The summary is completely factual.\n\nScore 1: The summary contains no relevant W from the original text\",\nScore 2: The summary contains only 1-2 Ws.\nScore 3: The summary lacks several relevant Ws.\nScore 4: The summary is lacking one relevant W.\t\t\nScore 5: The summary contains all the relevant Ws from the original text.\n\nProvide only the score for the criterion indicated below in the exact format. **Do not add any justification, explanation, or additional text**, just the score.\n\nExpected output format:\n- [5W1H]: score\n\n[SUMMARY] This is the summary to evaluate:\n{summary}\n\n[ORIGINAL DOCUMENT] This is the original document on which the summary is based.\n    {original_document}\n\nProvide your evaluation in the exact format: [5W1H]: (N) where N is a number from 1 to 5\n\"\"\"\n    \n    response = f\"[{target_metric.upper()}]: {int(round(score))}\"\n    return {\"prompt\": prompt, \"completion\": response}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:30:14.481409Z","iopub.execute_input":"2025-12-29T15:30:14.481661Z","iopub.status.idle":"2025-12-29T15:30:14.493150Z","shell.execute_reply.started":"2025-12-29T15:30:14.481636Z","shell.execute_reply":"2025-12-29T15:30:14.492503Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# FunciÃ³n prepare_metric_dataset ahora puede usar los 3 test sets\ndef prepare_metric_datasets(df_train, df_dev, df_test_es, df_test_gl, target_metric):\n    def build_data(df, split_name):\n        data = []\n        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Preparando {split_name} para {target_metric}\"):\n            data.append(construct_metric_prompt_simple(row, target_metric))\n        return data\n\n    train_data = build_data(df_train, \"train\")\n    dev_data = build_data(df_dev, \"dev\")\n    test_es_data = build_data(df_test_es, \"test_es\")\n    test_gl_data = build_data(df_test_gl, \"test_gl\")\n\n\n    train_dataset = Dataset.from_dict({\n        \"prompt\": [d[\"prompt\"] for d in train_data],\n        \"completion\": [d[\"completion\"] for d in train_data]\n    })\n    \n    dev_dataset = Dataset.from_dict({\n        \"prompt\": [d[\"prompt\"] for d in dev_data],\n        \"completion\": [d[\"completion\"] for d in dev_data]\n    })\n    \n    test_es_dataset = Dataset.from_dict({\n        \"prompt\": [d[\"prompt\"] for d in test_es_data],\n        \"completion\": [d[\"completion\"] for d in test_es_data]\n    })\n\n \n    test_gl_dataset = Dataset.from_dict({\n        \"prompt\": [d[\"prompt\"] for d in test_gl_data],\n        \"completion\": [d[\"completion\"] for d in test_gl_data]\n    })\n\n    return train_dataset, dev_dataset, test_es_dataset, test_gl_dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:30:14.494059Z","iopub.execute_input":"2025-12-29T15:30:14.494357Z","iopub.status.idle":"2025-12-29T15:30:14.510115Z","shell.execute_reply.started":"2025-12-29T15:30:14.494310Z","shell.execute_reply":"2025-12-29T15:30:14.509584Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"target_metric = \"5W1H\"\n#train_dataset, dev_dataset, test_dataset = prepare_metric_datasets(df_train_redondeo, df_dev_redondeo, df_test_redondeo, target_metric)\ntrain_dataset, dev_dataset, test_es_dataset,test_gl_dataset = prepare_metric_datasets(df_train_redondeo, df_dev_redondeo, df_test_es_redondeo, df_test_gl_redondeo, target_metric)\n\nprint(f\"\\nDataset de entrenamiento: {len(train_dataset)} ejemplos\")\nprint(f\"Dataset de desarrollo: {len(dev_dataset)} ejemplos\")\nprint(f\"Dataset de prueba es: {len(test_es_dataset)} ejemplos\")\nprint(f\"Dataset de prueba gl: {len(test_gl_dataset)} ejemplos\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:30:14.510866Z","iopub.execute_input":"2025-12-29T15:30:14.511142Z","iopub.status.idle":"2025-12-29T15:30:14.673671Z","shell.execute_reply.started":"2025-12-29T15:30:14.511097Z","shell.execute_reply":"2025-12-29T15:30:14.672888Z"}},"outputs":[{"name":"stderr","text":"Preparando train para 5W1H: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 624/624 [00:00<00:00, 19479.35it/s]\nPreparando dev para 5W1H: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 168/168 [00:00<00:00, 19268.86it/s]\nPreparando test_es para 5W1H: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198/198 [00:00<00:00, 18194.15it/s]\nPreparando test_gl para 5W1H: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:00<00:00, 20504.70it/s]","output_type":"stream"},{"name":"stdout","text":"\nDataset de entrenamiento: 624 ejemplos\nDataset de desarrollo: 168 ejemplos\nDataset de prueba es: 198 ejemplos\nDataset de prueba gl: 150 ejemplos\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# **CARGO EL MODELO**","metadata":{}},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/mistral-7b-bnb-4bit\", \n    max_seq_length = 5000,\n    dtype = None,\n    load_in_4bit = True,  \n)\nFastLanguageModel.for_training(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:30:14.674720Z","iopub.execute_input":"2025-12-29T15:30:14.674966Z","iopub.status.idle":"2025-12-29T15:31:06.705697Z","shell.execute_reply.started":"2025-12-29T15:30:14.674939Z","shell.execute_reply":"2025-12-29T15:31:06.705043Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.12.9: Fast Mistral patching. Transformers: 4.57.1.\n   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dbc1040728e4d998057a067af48f210"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/155 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80be67ca3c4f4c45abce219cde1d60e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4f0dd6743534a7d85167dd590989325"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"881b8e3128dd4d0fb34529e478104907"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ef6d27a305244fab88bc802e9f5df7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3babcd833dcd49c78e844cb7f1aa245a"}},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): MistralMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): MistralRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n)"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"#from kaggle_secrets import UserSecretsClient\n#user_secrets = UserSecretsClient()\n#secret_value_0 = user_secrets.get_secret(\"wandb\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:31:06.706576Z","iopub.execute_input":"2025-12-29T15:31:06.706870Z","iopub.status.idle":"2025-12-29T15:31:06.710140Z","shell.execute_reply.started":"2025-12-29T15:31:06.706843Z","shell.execute_reply":"2025-12-29T15:31:06.709401Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 8, \n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, #0.1\n    bias = \"none\",    \n    use_gradient_checkpointing = \"unsloth\", \n    random_state = 3407,\n    use_rslora = False,  \n    loftq_config = None, \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:31:06.711768Z","iopub.execute_input":"2025-12-29T15:31:06.712177Z","iopub.status.idle":"2025-12-29T15:31:12.953362Z","shell.execute_reply.started":"2025-12-29T15:31:06.712151Z","shell.execute_reply":"2025-12-29T15:31:12.952762Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.12.9 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:31:12.954294Z","iopub.execute_input":"2025-12-29T15:31:12.954627Z","iopub.status.idle":"2025-12-29T15:31:12.965607Z","shell.execute_reply.started":"2025-12-29T15:31:12.954587Z","shell.execute_reply":"2025-12-29T15:31:12.964991Z"}},"outputs":[{"name":"stdout","text":"trainable params: 20,971,520 || all params: 7,262,703,616 || trainable%: 0.2888\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"def preprocess(example):\n    prompt = example[\"prompt\"].strip()\n    completion = example[\"completion\"].strip()\n\n    full_text = f\"{prompt}\\n### Completion:\\n{completion}\"\n    input_text = f\"{prompt}\\n### Completion:\\n\"\n\n    tokenized = tokenizer(full_text, return_tensors=\"pt\", padding=False, truncation=True)\n    input_ids = tokenized[\"input_ids\"][0]\n    attention_mask = tokenized[\"attention_mask\"][0]\n\n    labels = input_ids.clone()\n    prompt_len = len(tokenizer(input_text, return_tensors=\"pt\").input_ids[0])\n    labels[:prompt_len] = -100 \n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels,\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:31:12.966480Z","iopub.execute_input":"2025-12-29T15:31:12.966820Z","iopub.status.idle":"2025-12-29T15:31:12.984492Z","shell.execute_reply.started":"2025-12-29T15:31:12.966793Z","shell.execute_reply":"2025-12-29T15:31:12.983609Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"train_dataset = train_dataset.map(preprocess)\ndev_dataset = dev_dataset.map(preprocess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:31:12.985517Z","iopub.execute_input":"2025-12-29T15:31:12.985995Z","iopub.status.idle":"2025-12-29T15:31:20.288286Z","shell.execute_reply.started":"2025-12-29T15:31:12.985967Z","shell.execute_reply":"2025-12-29T15:31:20.287538Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/624 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01b2c7b0fcab4f78bb21d2285c9294bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/168 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63eb2617eb2b424b8617e877f3ae79fd"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"class DataCollator:\n    def __call__(self, features):\n        # Asegurar que todos son tensores\n        input_ids = [torch.tensor(f[\"input_ids\"], dtype=torch.long) for f in features]\n        attention_mask = [torch.tensor(f[\"attention_mask\"], dtype=torch.long) for f in features]\n        labels = [torch.tensor(f[\"labels\"], dtype=torch.long) for f in features]\n\n        input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n        attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n        labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n\n        return {\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            \"labels\": labels,\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:31:20.289401Z","iopub.execute_input":"2025-12-29T15:31:20.289817Z","iopub.status.idle":"2025-12-29T15:31:20.295443Z","shell.execute_reply.started":"2025-12-29T15:31:20.289772Z","shell.execute_reply":"2025-12-29T15:31:20.294767Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"outputs\",\n    per_device_train_batch_size=1, #2 \n    gradient_accumulation_steps=8, #4\n    per_device_eval_batch_size=1,         # I added this\n    eval_accumulation_steps=10,            # I added this: Move eval results to CPU periodically\n    gradient_checkpointing=True, # I added this. O meu input Ã© longo e non quero erro OOM\n    learning_rate=5e-5,\n    num_train_epochs=3,\n    fp16=True,\n    bf16=False,\n    logging_steps=1,\n    eval_strategy=\"steps\",    \n    eval_steps=20,\n    save_strategy=\"steps\",          \n    save_steps=20,\n    save_total_limit=1,             \n    load_best_model_at_end=True,   \n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=None,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=dev_dataset,\n    data_collator=DataCollator(),\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:31:20.296286Z","iopub.execute_input":"2025-12-29T15:31:20.296631Z","iopub.status.idle":"2025-12-29T15:31:20.520633Z","shell.execute_reply.started":"2025-12-29T15:31:20.296594Z","shell.execute_reply":"2025-12-29T15:31:20.520087Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# **ENTRENO EL MODELO**","metadata":{}},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:31:20.521591Z","iopub.execute_input":"2025-12-29T15:31:20.521963Z","execution_failed":"2025-12-30T08:40:24.069Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 624 | Num Epochs = 3 | Total steps = 234\nO^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 8 x 1) = 8\n \"-____-\"     Trainable parameters = 20,971,520 of 7,262,703,616 (0.29% trained)\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='102' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [102/234 1:52:26 < 2:28:25, 0.01 it/s, Epoch 1.29/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.175000</td>\n      <td>0.159149</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.090100</td>\n      <td>0.148994</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.144600</td>\n      <td>0.153411</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.156500</td>\n      <td>0.153216</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.050900</td>\n      <td>0.158901</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Unsloth: Not an error, but MistralForCausalLM does not accept `num_items_in_batch`.\nUsing gradient accumulation will be very slightly less accurate.\nRead more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# **GUARDO EL MODELO ENTRENADO**","metadata":{}},{"cell_type":"code","source":"trainer.save_model(\"./output/final_model\")\ntokenizer.save_pretrained(\"./output/final_model\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.070Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name =  \"./output/final_model\",\n    max_seq_length = 5000,\n    load_in_4bit = True,\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.070Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **LAS REFERENCIAS**","metadata":{}},{"cell_type":"code","source":"def get_references(eval_dataset):\n    respuestas = []\n    for x in eval_dataset:\n        respuesta = [x[\"response\"]]\n        match = re.search(r\"\\[5W1H\\]:\\s*(\\d+)\", respuesta[0])\n        if match:\n            respuestas.append(int(match.group(1)))\n        else: \n            respuestas.append(None)\n\n    return respuestas","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.070Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_eval_dataset_es = []\nfor i in range(len(test_es_dataset)):\n    test_eval_dataset_es.append({\n        \"prompt\": test_es_dataset[i][\"prompt\"],\n        \"response\": test_es_dataset[i][\"completion\"]\n    })","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.070Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"referencias_es = get_references(test_eval_dataset_es)\nprint(\"Referencias ES:\", referencias_es)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.070Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_eval_dataset_gl = []\nfor i in range(len(test_gl_dataset)):\n    test_eval_dataset_gl.append({\n        \"prompt\": test_gl_dataset[i][\"prompt\"],\n        \"response\": test_gl_dataset[i][\"completion\"]\n    })\n    \nreferencias_gl = get_references(test_eval_dataset_gl)\nprint(\"Referencias GL:\", referencias_gl)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.071Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **EVALUO EL MODELO**","metadata":{}},{"cell_type":"code","source":"def evaluate_metric_model(model, dataset, tokenizer, metric):\n    all_predictions = []\n    model.eval()\n    all_predictions = []\n    all_references = []\n\n    \n    # Iterate over the dataset\n    for idx, example in enumerate(tqdm(dataset, desc=f\"Evaluating {metric} model\")):\n\n        prompt = example[\"prompt\"] \n        \n        inputs = tokenizer(\n            prompt,\n            return_tensors=\"pt\",\n            truncation=True,\n            max_length=5000,\n            padding=True\n        )\n        inputs = inputs.to(model.device)\n        with torch.no_grad():\n            outputs = model.generate(\n                input_ids=inputs[\"input_ids\"],\n                attention_mask=inputs[\"attention_mask\"],\n                max_new_tokens=50,\n                do_sample=False,  # GeneraciÃ³n determinista (greedy)\n                pad_token_id=tokenizer.eos_token_id\n            )\n        \n        prompt_length = len(inputs[\"input_ids\"][0])\n        new_tokens = outputs[0][prompt_length:]\n        generated_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n        match = re.search(r\"\\[5W1H\\]:\\s*(\\d+)\", generated_text)\n        print(generated_text)\n        if match:\n            all_predictions.append(float(match.group(1)))\n        else:\n            all_predictions.append(None)\n\n    \n    return all_predictions\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.072Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **TEST ES**","metadata":{}},{"cell_type":"code","source":"predictions_es = evaluate_metric_model(model, test_es_dataset,  tokenizer, \"5W1H\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"ES test:\", predictions_es)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cantidad_none = predictions_es.count(None)\ntotal_es = len(predictions_es)\nporcentaje_es = cantidad_none / total_es\n\nprint(f\"Cantidad de valores None: {cantidad_none}, Total de predicciones: {total_es}\")\nprint(f\"Porcentaje de Nones: {porcentaje_es:.2%}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.072Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **QUITO LOS NONE**","metadata":{}},{"cell_type":"code","source":"filtrados = [(h, p) for h, p in zip(referencias_es, predictions_es) if h is not None and p is not None]\nhum_limpio, predictions_limpio = zip(*filtrados)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(hum_limpio)\nprint(predictions_limpio)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.073Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **MÃ‰TRICAS**","metadata":{}},{"cell_type":"markdown","source":"## **SPEARMANR**","metadata":{}},{"cell_type":"code","source":"# Mide si el modelo puede ordenar los modelos de peor a mejor \n# en comparaciÃ³n con las puntuaciones humanas (no exactamente la misma puntuaciÃ³n)\ns, p = spearmanr(hum_limpio, predictions_limpio)\nprint(f\"Spearman ES: {s:.3f}, p-value: {p:.3f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.073Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **KENDALLTAU**","metadata":{}},{"cell_type":"code","source":"# Mide la capacidad para ordenar los resumenes segÃºn su calidad, \n# pero se calcula por parejas (de estos dos cuÃ¡l es el mejor?)\ntau, p_value = scipy.stats.kendalltau(hum_limpio, predictions_limpio)\nprint(f\"Kendalltau ES: {tau:.3f}, p-value: {p_value:.3f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.074Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **MAE**","metadata":{}},{"cell_type":"code","source":"# Error medio absoluto\n# Mide la distancia media entre las puntuaciones predichas por los modelos \n# y las dadas por los humanos\n# Es decir, menos de 0,5 (ej.: humano -> 5, modelo -> 4.60)\nmae = np.mean(np.abs(np.array(hum_limpio) - np.array(predictions_limpio)))\nprint(f\"MAE ES: {mae}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.074Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **TEST GL**","metadata":{}},{"cell_type":"code","source":"predictions_gl = evaluate_metric_model(model, test_gl_dataset,  tokenizer, \"5W1H\")\nprint(\"GL test:\", predictions_gl)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.074Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cantidad_none_gl = predictions_gl.count(None)\ntotal_gl = len(predictions_gl)\nporcentaje_gl = cantidad_none_gl / total_gl\n\nprint(f\"Cantidad de valores None: {cantidad_none_gl}, Total de predicciones: {total_gl}\")\nprint(f\"Porcentaje de Nones: {porcentaje_gl:.2%}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.074Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **QUITO LOS NONE**","metadata":{}},{"cell_type":"code","source":"filtrados_gl = [(h, p) for h, p in zip(referencias_gl, predictions_gl) if h is not None and p is not None]\nhum_limpio_gl, predictions_limpio_gl = zip(*filtrados_gl)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.074Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(hum_limpio_gl)\nprint(predictions_limpio_gl)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.074Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **MÃ‰TRICAS**","metadata":{}},{"cell_type":"markdown","source":"## **SPEARMANR**","metadata":{}},{"cell_type":"code","source":"# Mide si el modelo puede ordenar los modelos de peor a mejor \n# en comparaciÃ³n con las puntuaciones humanas (no exactamente la misma puntuaciÃ³n)\ns, p = spearmanr(hum_limpio_gl, predictions_limpio_gl)\nprint(f\"Spearman GL: {s:.3f}, p-value: {p:.3f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.075Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **KENDALLTAU**","metadata":{}},{"cell_type":"code","source":"# Mide la capacidad para ordenar los resumenes segÃºn su calidad, \n# pero se calcula por parejas (de estos dos cuÃ¡l es el mejor?)\ntau, p_value = scipy.stats.kendalltau(hum_limpio_gl, predictions_limpio_gl)\nprint(f\"Kendalltau GL: {tau:.3f}, p-value: {p_value:.3f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.075Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **MAE**","metadata":{}},{"cell_type":"code","source":"# Error medio absoluto\n# Mide la distancia media entre las puntuaciones predichas por los modelos \n# y las dadas por los humanos\n# Es decir, menos de 0,5 (ej.: humano -> 5, modelo -> 4.60)\nmae = np.mean(np.abs(np.array(hum_limpio_gl) - np.array(predictions_limpio_gl)))\nprint(f\"MAE GL: {mae}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-30T08:40:24.075Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}