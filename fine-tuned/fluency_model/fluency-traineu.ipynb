{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13970127,"sourceType":"datasetVersion","datasetId":8906005},{"sourceId":14191599,"sourceType":"datasetVersion","datasetId":9049029},{"sourceId":14191605,"sourceType":"datasetVersion","datasetId":9049035}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"WANDB_MODE\"] = \"disabled\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:13:26.925545Z","iopub.execute_input":"2025-12-21T22:13:26.926083Z","iopub.status.idle":"2025-12-21T22:13:26.932418Z","shell.execute_reply.started":"2025-12-21T22:13:26.926053Z","shell.execute_reply":"2025-12-21T22:13:26.931707Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install --upgrade unsloth peft bitsandbytes accelerate trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:13:26.933589Z","iopub.execute_input":"2025-12-21T22:13:26.933822Z","iopub.status.idle":"2025-12-21T22:16:51.645620Z","shell.execute_reply.started":"2025-12-21T22:13:26.933800Z","shell.execute_reply":"2025-12-21T22:16:51.644841Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.12.8-py3-none-any.whl.metadata (65 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\nCollecting peft\n  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nCollecting accelerate\n  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\nCollecting trl\n  Downloading trl-0.26.2-py3-none-any.whl.metadata (11 kB)\nCollecting unsloth_zoo>=2025.12.6 (from unsloth)\n  Downloading unsloth_zoo-2025.12.6-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.8.0+cu126)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.23.0+cu126)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\nCollecting tyro (from unsloth)\n  Downloading tyro-1.0.3-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.4.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\nCollecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth)\n  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.2)\nRequirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.57.1)\nCollecting trl\n  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.3)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.20.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\nCollecting multiprocess<0.70.17 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\nCollecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (0.22.1)\nCollecting torchao>=0.13.0 (from unsloth_zoo>=2025.12.6->unsloth)\n  Downloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.12.6->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.6->unsloth) (11.3.0)\nCollecting msgspec (from unsloth_zoo>=2025.12.6->unsloth)\n  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.10.2.21->torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.1.2->torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nccl-cu12==2.27.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.0.4->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (0.17.0)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\nDownloading unsloth-2025.12.8-py3-none-any.whl (376 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading peft-0.18.0-py3-none-any.whl (556 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.12.6-py3-none-any.whl (289 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-1.0.3-py3-none-any.whl (180 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torchao, triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multiprocess, msgspec, fsspec, tyro, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, accelerate, trl, peft, unsloth_zoo, unsloth\n  Attempting uninstall: torchao\n    Found existing installation: torchao 0.10.0\n    Uninstalling torchao-0.10.0:\n      Successfully uninstalled torchao-0.10.0\n  Attempting uninstall: triton\n    Found existing installation: triton 3.4.0\n    Uninstalling triton-3.4.0:\n      Successfully uninstalled triton-3.4.0\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.6.77\n    Uninstalling nvidia-nvtx-cu12-12.6.77:\n      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n  Attempting uninstall: nvidia-nvshmem-cu12\n    Found existing installation: nvidia-nvshmem-cu12 3.4.5\n    Uninstalling nvidia-nvshmem-cu12-3.4.5:\n      Successfully uninstalled nvidia-nvshmem-cu12-3.4.5\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.27.3\n    Uninstalling nvidia-nccl-cu12-2.27.3:\n      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufile-cu12\n    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.18\n    Uninstalling multiprocess-0.70.18:\n      Successfully uninstalled multiprocess-0.70.18\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.10.0\n    Uninstalling fsspec-2025.10.0:\n      Successfully uninstalled fsspec-2025.10.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.8.0+cu126\n    Uninstalling torch-2.8.0+cu126:\n      Successfully uninstalled torch-2.8.0+cu126\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.4.1\n    Uninstalling datasets-4.4.1:\n      Successfully uninstalled datasets-4.4.1\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.23.0+cu126\n    Uninstalling torchvision-0.23.0+cu126:\n      Successfully uninstalled torchvision-0.23.0+cu126\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.11.0\n    Uninstalling accelerate-1.11.0:\n      Successfully uninstalled accelerate-1.11.0\n  Attempting uninstall: peft\n    Found existing installation: peft 0.17.1\n    Uninstalling peft-0.17.1:\n      Successfully uninstalled peft-0.17.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nfastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.1 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\ntorchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-1.12.0 bitsandbytes-0.49.0 cut_cross_entropy-25.1.1 datasets-4.3.0 fsspec-2025.9.0 msgspec-0.20.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 peft-0.18.0 torch-2.9.1 torchao-0.15.0 torchvision-0.24.1 triton-3.5.1 trl-0.24.0 tyro-1.0.3 unsloth-2025.12.8 unsloth_zoo-2025.12.6 xformers-0.0.33.post2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:16:51.647283Z","iopub.execute_input":"2025-12-21T22:16:51.647562Z","iopub.status.idle":"2025-12-21T22:16:55.806220Z","shell.execute_reply.started":"2025-12-21T22:16:51.647533Z","shell.execute_reply":"2025-12-21T22:16:55.805500Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\nRequirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.6\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **IMPORTS**","metadata":{}},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:16:55.807452Z","iopub.execute_input":"2025-12-21T22:16:55.807775Z","iopub.status.idle":"2025-12-21T22:17:43.773499Z","shell.execute_reply.started":"2025-12-21T22:16:55.807738Z","shell.execute_reply":"2025-12-21T22:17:43.772893Z"}},"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-12-21 22:17:06.875542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766355427.246141      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766355427.349655      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766355428.251757      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766355428.251790      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766355428.251793      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766355428.251795      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import scipy\nimport json\nimport re\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nimport evaluate\nfrom scipy.stats import spearmanr, kendalltau\nfrom datasets import Dataset\nfrom tqdm import tqdm\nimport glob\n\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling, EarlyStoppingCallback\nfrom peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training, PeftModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:17:43.774941Z","iopub.execute_input":"2025-12-21T22:17:43.775628Z","iopub.status.idle":"2025-12-21T22:17:43.981606Z","shell.execute_reply.started":"2025-12-21T22:17:43.775598Z","shell.execute_reply":"2025-12-21T22:17:43.981013Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# **CARGO LOS DATOS**","metadata":{}},{"cell_type":"code","source":"def load_jsonl(path):\n    data = []\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                data.append(json.loads(line))\n        return pd.DataFrame(data)\n    except FileNotFoundError:\n        print(f\"Error: No se encontrÃ³ el archivo {path}\")\n        return pd.DataFrame()\n\n#df_es = load_jsonl(\"/kaggle/input/basse-es-jsonl/BASSE_es.jsonl\")\ndf_eu = load_jsonl(\"/kaggle/input/basse-eu-jsonl/BASSE_eu.jsonl\")\ndf_test_gl = load_jsonl(\"/kaggle/input/basse-gl-jsonl/BASSE.gl.jsonl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:19:32.060446Z","iopub.execute_input":"2025-12-21T22:19:32.061257Z","iopub.status.idle":"2025-12-21T22:19:32.108577Z","shell.execute_reply.started":"2025-12-21T22:19:32.061219Z","shell.execute_reply":"2025-12-21T22:19:32.108011Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# **DIVIDO EL CONJUNTO DE DATOS**","metadata":{}},{"cell_type":"code","source":"# 1 -> Separamos test sets para ES (10%)\n#train_dev_es, test_es = train_test_split(df_es, test_size=0.1, random_state=42, shuffle=True)\ntrain_dev_eu, test_eu = train_test_split(df_eu, test_size=0.2, random_state=42, shuffle=True)\n# 2 -> Creamos train sets (80% total) y dev sets (10% total) para ES y EU\n#train_es, dev_es = train_test_split(train_dev_es, test_size=0.1111, random_state=42, shuffle=True)\ntrain_eu, dev_eu = train_test_split(train_dev_eu, test_size=8/36, random_state=42, shuffle=True)\n\n# 3 -> Ajustamos el tamaÃ±o del train set (train_set_length ==> modeloES = modeloEU = modeloES-EU)\n#train_es_fewshot = train_es.head(20)\n#train_eu_fewshot = train_eu.head(20)\n\n# 4 -> Shuffle ES + EU\ndf_train = train_eu\ndf_dev = dev_eu\n\n# 5 -> Ponemos nombres claros a los test\ndf_test_eu = test_eu.reset_index(drop=True)\n# df_test_gl \n\nprint(f\"TRAIN:    {len(df_train)}\")\nprint(f\"DEV:      {len(df_dev)}\")\nprint(\"-\" * 30)\nprint(f\"TEST EU:  {len(df_test_eu)}\")\nprint(f\"TEST GL:  {len(df_test_gl)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:19:34.911536Z","iopub.execute_input":"2025-12-21T22:19:34.912226Z","iopub.status.idle":"2025-12-21T22:19:34.936780Z","shell.execute_reply.started":"2025-12-21T22:19:34.912186Z","shell.execute_reply":"2025-12-21T22:19:34.936114Z"}},"outputs":[{"name":"stdout","text":"TRAIN:    28\nDEV:      8\n------------------------------\nTEST EU:  9\nTEST GL:  15\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# **COMO UN RESUMEN TIENE MAS DE UNA ANOTACIÃ“N, HAGO LA MEDIA**","metadata":{}},{"cell_type":"code","source":"def extraer_resumenes(df):\n    res = []\n\n    for _, row in df.iterrows():\n        original = row.get('original_document', '')\n        \n        model_data = row.get('model_summaries', {})\n        \n        if isinstance(model_data, dict):\n            for model_name, contenido in model_data.items():\n                resumen = contenido.get(\"summ\", None)\n                anns = contenido.get(\"anns\", {})\n                \n                fluency_vals = anns.get(\"Fluency\", None)\n\n                if resumen and fluency_vals:\n                    if isinstance(fluency_vals, list):\n                        score = np.mean(fluency_vals)\n                    else:\n                        score = float(fluency_vals)\n                        \n                    media = int(round(score))\n                    \n                    res.append((resumen, media, original))\n\n    return pd.DataFrame(res, columns=[\"resumen\", \"fluency\", \"original_document\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:19:48.195226Z","iopub.execute_input":"2025-12-21T22:19:48.195581Z","iopub.status.idle":"2025-12-21T22:19:48.201843Z","shell.execute_reply.started":"2025-12-21T22:19:48.195549Z","shell.execute_reply":"2025-12-21T22:19:48.201085Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"df_train_redondeo = extraer_resumenes(df_train)\ndf_dev_redondeo = extraer_resumenes(df_dev)\ndf_test_eu_redondeo = extraer_resumenes(df_test_eu)\ndf_test_gl_redondeo = extraer_resumenes(df_test_gl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:19:48.203113Z","iopub.execute_input":"2025-12-21T22:19:48.203405Z","iopub.status.idle":"2025-12-21T22:19:48.245573Z","shell.execute_reply.started":"2025-12-21T22:19:48.203362Z","shell.execute_reply":"2025-12-21T22:19:48.244808Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print(f\"Ejemplos procesados TRAIN: {len(df_train_redondeo)}\")\nprint(f\"Ejemplos procesados DEV: {len(df_dev_redondeo)}\")\nprint(f\"Ejemplos procesados TEST eu: {len(df_test_eu_redondeo)}\")\nprint(f\"Ejemplos procesados TEST gl: {len(df_test_gl_redondeo)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:19:48.246527Z","iopub.execute_input":"2025-12-21T22:19:48.246793Z","iopub.status.idle":"2025-12-21T22:19:48.252923Z","shell.execute_reply.started":"2025-12-21T22:19:48.246766Z","shell.execute_reply":"2025-12-21T22:19:48.252345Z"}},"outputs":[{"name":"stdout","text":"Ejemplos procesados TRAIN: 624\nEjemplos procesados DEV: 168\nEjemplos procesados TEST eu: 198\nEjemplos procesados TEST gl: 150\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# **CONSTRUYO EL PROMPT**","metadata":{}},{"cell_type":"code","source":"def construct_metric_prompt_simple(row, target_metric):\n    \"\"\"Construye un prompt de instrucciÃ³n para evaluar un resumen usando una mÃ©trica especÃ­fica\"\"\"\n    \n    summary = row['resumen']\n    score = row[target_metric]\n    \n    prompt = f\"\"\"[INSTRUCCIÃ“N]\nAs an expert evaluator, analyze the following summary.\nEvaluate solely the {target_metric} criterion on a scale of 1 to 5, where 1 is the lowest score and 5 is the highest.\n\nCriterion: Fluency: the quality of individual sentences. Drawing again from the DUC quality guidelines, sentences in the summary 'should have no formatting problems, \ncapitalization errors or obviously ungrammatical sentences (e.g., fragments, missing components) that make the text difficult to read.' \nIs the summary well written following the grammar and spelling conventions for the language? If it has errors, we penalize it. We only take grammar and fluency into account. \nWhile the style can sometimes be forced, if it is grammatically correct, we give full points. \n\nScore 1: There are many important grammatical errors or the summary mixes language varieties/dialects in a very unnatural and uncomfortable way or the summary is not written in the language it is asked for.\nScore 2: There are various important grammatical errors or the summary mixes language varieties/dialects in an unnatural and uncomfortable way.\nScore 3: There are grammatical errors of lesser importance or the summary mixes language varieties/dialects in a somewhat unnatural and uncomfortable way.\nScore 4: There are few grammatical errors.\t\t\nScore 5: There is no grammatical or spelling error and the variety of the language/dialect used is coherent.\n\nProvide only the score for the criterion indicated below in the exact format. **Do not add any justification, explanation, or additional text**, just the score.\n\nExpected output format:\n- [FLUENCY]: score\n\n[SUMMARY] This is the summary to evaluate:\n{summary}\n\nProvide your evaluation in the exact format: [FLUENCY]: (N) where N is a number from 1 to 5\n\"\"\"\n    \n    response = f\"[{target_metric.upper()}]: {int(round(score))}\"\n    return {\"prompt\": prompt, \"completion\": response}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:19:48.254312Z","iopub.execute_input":"2025-12-21T22:19:48.254604Z","iopub.status.idle":"2025-12-21T22:19:48.269340Z","shell.execute_reply.started":"2025-12-21T22:19:48.254568Z","shell.execute_reply":"2025-12-21T22:19:48.268853Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# FunciÃ³n prepare_metric_dataset ahora puede usar los 3 test sets\ndef prepare_metric_datasets(df_train, df_dev, df_test_eu, df_test_gl, target_metric):\n    def build_data(df, split_name):\n        data = []\n        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Preparando {split_name} para {target_metric}\"):\n            data.append(construct_metric_prompt_simple(row, target_metric))\n        return data\n\n    train_data = build_data(df_train, \"train\")\n    dev_data = build_data(df_dev, \"dev\")\n    test_eu_data = build_data(df_test_eu, \"test_eu\")\n    test_gl_data = build_data(df_test_gl, \"test_gl\")\n\n\n    train_dataset = Dataset.from_dict({\n        \"prompt\": [d[\"prompt\"] for d in train_data],\n        \"completion\": [d[\"completion\"] for d in train_data]\n    })\n    \n    dev_dataset = Dataset.from_dict({\n        \"prompt\": [d[\"prompt\"] for d in dev_data],\n        \"completion\": [d[\"completion\"] for d in dev_data]\n    })\n    \n    test_eu_dataset = Dataset.from_dict({\n        \"prompt\": [d[\"prompt\"] for d in test_eu_data],\n        \"completion\": [d[\"completion\"] for d in test_eu_data]\n    })\n\n \n    test_gl_dataset = Dataset.from_dict({\n        \"prompt\": [d[\"prompt\"] for d in test_gl_data],\n        \"completion\": [d[\"completion\"] for d in test_gl_data]\n    })\n\n    return train_dataset, dev_dataset, test_eu_dataset, test_gl_dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:19:48.270099Z","iopub.execute_input":"2025-12-21T22:19:48.270344Z","iopub.status.idle":"2025-12-21T22:19:48.285846Z","shell.execute_reply.started":"2025-12-21T22:19:48.270319Z","shell.execute_reply":"2025-12-21T22:19:48.285149Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"target_metric = \"fluency\"\n#train_dataset, dev_dataset, test_dataset = prepare_metric_datasets(df_train_redondeo, df_dev_redondeo, df_test_redondeo, target_metric)\ntrain_dataset, dev_dataset, test_eu_dataset,test_gl_dataset = prepare_metric_datasets(df_train_redondeo, df_dev_redondeo, df_test_eu_redondeo, df_test_gl_redondeo, target_metric)\n\nprint(f\"\\nDataset de entrenamiento: {len(train_dataset)} ejemplos\")\nprint(f\"Dataset de desarrollo: {len(dev_dataset)} ejemplos\")\nprint(f\"Dataset de prueba es: {len(test_eu_dataset)} ejemplos\")\nprint(f\"Dataset de prueba gl: {len(test_gl_dataset)} ejemplos\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:19:48.286676Z","iopub.execute_input":"2025-12-21T22:19:48.286973Z","iopub.status.idle":"2025-12-21T22:19:48.418846Z","shell.execute_reply.started":"2025-12-21T22:19:48.286949Z","shell.execute_reply":"2025-12-21T22:19:48.418199Z"}},"outputs":[{"name":"stderr","text":"Preparando train para fluency: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 624/624 [00:00<00:00, 23477.90it/s]\nPreparando dev para fluency: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 168/168 [00:00<00:00, 25280.49it/s]\nPreparando test_eu para fluency: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198/198 [00:00<00:00, 23092.41it/s]\nPreparando test_gl para fluency: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:00<00:00, 24394.94it/s]","output_type":"stream"},{"name":"stdout","text":"\nDataset de entrenamiento: 624 ejemplos\nDataset de desarrollo: 168 ejemplos\nDataset de prueba es: 198 ejemplos\nDataset de prueba gl: 150 ejemplos\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# **CARGO EL MODELO**","metadata":{}},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/mistral-7b-bnb-4bit\", \n    max_seq_length = 5000,\n    dtype = None,\n    load_in_4bit = True,  \n)\nFastLanguageModel.for_training(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:19:48.420270Z","iopub.execute_input":"2025-12-21T22:19:48.420576Z","iopub.status.idle":"2025-12-21T22:20:10.308342Z","shell.execute_reply.started":"2025-12-21T22:19:48.420550Z","shell.execute_reply":"2025-12-21T22:20:10.307508Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.12.8: Fast Mistral patching. Transformers: 4.57.1.\n   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2f6980ad1de44f4b4059176228ab2bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/155 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c13278a48375450aa664011ff7610c72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c8210013b8545d8bc5d8fbb4f9a5082"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1e560da56cc420d9055c344d2707eda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbda141b3fd44c9d8dea8b03d7a5b684"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff607891dd2b416cabd05f40d7e94a0c"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): MistralMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): MistralRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"#from kaggle_secrets import UserSecretsClient\n#user_secrets = UserSecretsClient()\n#secret_value_0 = user_secrets.get_secret(\"wandb\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:20:10.309360Z","iopub.execute_input":"2025-12-21T22:20:10.309716Z","iopub.status.idle":"2025-12-21T22:20:10.313249Z","shell.execute_reply.started":"2025-12-21T22:20:10.309677Z","shell.execute_reply":"2025-12-21T22:20:10.312509Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#wandb.login(key=secret_value_0)\n#run = wandb.init(\n#    project='Coherence_TFG_Leire_SinDataAumentation',\n#    name=\"run_lora_r8_bs4_alpha16_balanceado\",\n#    job_type=\"training\",\n#    anonymous=\"allow\",\n#    config={\n#        \"batch_size\": 4,\n#        \"gradient_accumulation_steps\": 2,\n#        \"learning_rate\": 5e-5,\n#        \"lora_r\": 8,\n#        \"lora_alpha\": 16,\n#        \"dropout\": 0.1,\n#        \"epochs\": 2,\n#    },\n#    reinit=True\n#)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:20:10.314271Z","iopub.execute_input":"2025-12-21T22:20:10.314664Z","iopub.status.idle":"2025-12-21T22:20:14.126671Z","shell.execute_reply.started":"2025-12-21T22:20:10.314636Z","shell.execute_reply":"2025-12-21T22:20:14.125416Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 8, \n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0.1,\n    bias = \"none\",    \n    use_gradient_checkpointing = \"unsloth\", \n    random_state = 3407,\n    use_rslora = False,  \n    loftq_config = None, \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:20:14.127618Z","iopub.execute_input":"2025-12-21T22:20:14.127857Z","iopub.status.idle":"2025-12-21T22:20:21.514853Z","shell.execute_reply.started":"2025-12-21T22:20:14.127832Z","shell.execute_reply":"2025-12-21T22:20:21.514018Z"}},"outputs":[{"name":"stderr","text":"Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\nUnsloth will patch all other layers, except LoRA matrices, causing a performance hit.\nUnsloth 2025.12.8 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:20:21.515801Z","iopub.execute_input":"2025-12-21T22:20:21.516116Z","iopub.status.idle":"2025-12-21T22:20:21.527632Z","shell.execute_reply.started":"2025-12-21T22:20:21.516087Z","shell.execute_reply":"2025-12-21T22:20:21.526853Z"}},"outputs":[{"name":"stdout","text":"trainable params: 20,971,520 || all params: 7,262,703,616 || trainable%: 0.2888\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"def preprocess(example):\n    prompt = example[\"prompt\"].strip()\n    completion = example[\"completion\"].strip()\n\n    full_text = f\"{prompt}\\n### Completion:\\n{completion}\"\n    input_text = f\"{prompt}\\n### Completion:\\n\"\n\n    tokenized = tokenizer(full_text, return_tensors=\"pt\", padding=False, truncation=True)\n    input_ids = tokenized[\"input_ids\"][0]\n    attention_mask = tokenized[\"attention_mask\"][0]\n\n    labels = input_ids.clone()\n    prompt_len = len(tokenizer(input_text, return_tensors=\"pt\").input_ids[0])\n    labels[:prompt_len] = -100 \n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels,\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:20:21.528385Z","iopub.execute_input":"2025-12-21T22:20:21.528628Z","iopub.status.idle":"2025-12-21T22:20:24.637709Z","shell.execute_reply.started":"2025-12-21T22:20:21.528604Z","shell.execute_reply":"2025-12-21T22:20:24.637005Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"train_dataset = train_dataset.map(preprocess)\ndev_dataset = dev_dataset.map(preprocess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:20:24.640331Z","iopub.execute_input":"2025-12-21T22:20:24.640602Z","iopub.status.idle":"2025-12-21T22:20:27.816306Z","shell.execute_reply.started":"2025-12-21T22:20:24.640574Z","shell.execute_reply":"2025-12-21T22:20:27.815514Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/624 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1ac0a74508a4dcc9562b12b9a10133a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/168 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d867d06e7838480e93a9f153716fc4d6"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"class DataCollator:\n    def __call__(self, features):\n        # Asegurar que todos son tensores\n        input_ids = [torch.tensor(f[\"input_ids\"], dtype=torch.long) for f in features]\n        attention_mask = [torch.tensor(f[\"attention_mask\"], dtype=torch.long) for f in features]\n        labels = [torch.tensor(f[\"labels\"], dtype=torch.long) for f in features]\n\n        input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n        attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n        labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n\n        return {\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            \"labels\": labels,\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:20:27.817332Z","iopub.execute_input":"2025-12-21T22:20:27.817802Z","iopub.status.idle":"2025-12-21T22:20:27.823059Z","shell.execute_reply.started":"2025-12-21T22:20:27.817773Z","shell.execute_reply":"2025-12-21T22:20:27.822501Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"outputs\",\n    per_device_train_batch_size=2, \n    gradient_accumulation_steps=4, \n    gradient_checkpointing=True, # I added this. O meu input Ã© longo e non quero erro OOM\n    learning_rate=5e-5,\n    num_train_epochs=3,\n    fp16=True,\n    bf16=False,\n    logging_steps=1,\n    eval_strategy=\"steps\",    \n    eval_steps=20,\n    save_strategy=\"steps\",          \n    save_steps=20,\n    save_total_limit=1,             \n    load_best_model_at_end=True,   \n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=None,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=dev_dataset,\n    data_collator=DataCollator(),\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:20:27.824092Z","iopub.execute_input":"2025-12-21T22:20:27.824510Z","iopub.status.idle":"2025-12-21T22:20:28.131806Z","shell.execute_reply.started":"2025-12-21T22:20:27.824473Z","shell.execute_reply":"2025-12-21T22:20:28.131138Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# **ENTRENO EL MODELO**","metadata":{}},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:20:28.132786Z","iopub.execute_input":"2025-12-21T22:20:28.133072Z","iopub.status.idle":"2025-12-22T00:19:43.895081Z","shell.execute_reply.started":"2025-12-21T22:20:28.133043Z","shell.execute_reply":"2025-12-22T00:19:43.894507Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 624 | Num Epochs = 3 | Total steps = 234\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n \"-____-\"     Trainable parameters = 20,971,520 of 7,262,703,616 (0.29% trained)\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [234/234 1:58:45, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.134100</td>\n      <td>0.193542</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.178700</td>\n      <td>0.187321</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.192700</td>\n      <td>0.171107</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.134300</td>\n      <td>0.172737</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.167000</td>\n      <td>0.161422</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.072800</td>\n      <td>0.164784</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.129700</td>\n      <td>0.144955</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.122600</td>\n      <td>0.146354</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.094100</td>\n      <td>0.142277</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.140200</td>\n      <td>0.135225</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.159100</td>\n      <td>0.137008</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Unsloth: Not an error, but MistralForCausalLM does not accept `num_items_in_batch`.\nUsing gradient accumulation will be very slightly less accurate.\nRead more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"# **GUARDO EL MODELO ENTRENADO**","metadata":{}},{"cell_type":"code","source":"trainer.save_model(\"./output/final_model\")\ntokenizer.save_pretrained(\"./output/final_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:19:43.896236Z","iopub.execute_input":"2025-12-22T00:19:43.896552Z","iopub.status.idle":"2025-12-22T00:19:44.256121Z","shell.execute_reply.started":"2025-12-22T00:19:43.896514Z","shell.execute_reply":"2025-12-22T00:19:44.255583Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"('./output/final_model/tokenizer_config.json',\n './output/final_model/special_tokens_map.json',\n './output/final_model/tokenizer.model',\n './output/final_model/added_tokens.json',\n './output/final_model/tokenizer.json')"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name =  \"./output/final_model\",\n    max_seq_length = 5000,\n    load_in_4bit = True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:19:44.257034Z","iopub.execute_input":"2025-12-22T00:19:44.257290Z","iopub.status.idle":"2025-12-22T00:19:58.682720Z","shell.execute_reply.started":"2025-12-22T00:19:44.257265Z","shell.execute_reply":"2025-12-22T00:19:58.681855Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.12.8: Fast Mistral patching. Transformers: 4.57.1.\n   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"name":"stderr","text":"Unsloth: Will load ./output/final_model as a legacy tokenizer.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"# **LAS REFERENCIAS**","metadata":{}},{"cell_type":"code","source":"def get_references(eval_dataset):\n    respuestas = []\n    for x in eval_dataset:\n        respuesta = [x[\"response\"]]\n        match = re.search(r\"\\[FLUENCY\\]:\\s*(\\d+)\", respuesta[0])\n        if match:\n            respuestas.append(int(match.group(1)))\n        else: \n            respuestas.append(None)\n\n    return respuestas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:19:58.683734Z","iopub.execute_input":"2025-12-22T00:19:58.684032Z","iopub.status.idle":"2025-12-22T00:19:58.689023Z","shell.execute_reply.started":"2025-12-22T00:19:58.684005Z","shell.execute_reply":"2025-12-22T00:19:58.688345Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"test_eval_dataset_eu = []\nfor i in range(len(test_eu_dataset)):\n    test_eval_dataset_eu.append({\n        \"prompt\": test_eu_dataset[i][\"prompt\"],\n        \"response\": test_eu_dataset[i][\"completion\"]\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:19:58.689856Z","iopub.execute_input":"2025-12-22T00:19:58.690060Z","iopub.status.idle":"2025-12-22T00:19:58.725313Z","shell.execute_reply.started":"2025-12-22T00:19:58.690037Z","shell.execute_reply":"2025-12-22T00:19:58.724649Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"referencias_eu = get_references(test_eval_dataset_eu)\nprint(\"Referencias EU:\", referencias_eu)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:19:58.726328Z","iopub.execute_input":"2025-12-22T00:19:58.726677Z","iopub.status.idle":"2025-12-22T00:19:58.730732Z","shell.execute_reply.started":"2025-12-22T00:19:58.726645Z","shell.execute_reply":"2025-12-22T00:19:58.730143Z"}},"outputs":[{"name":"stdout","text":"Referencias EU: [5, 3, 3, 5, 1, 2, 3, 2, 5, 5, 5, 5, 4, 5, 5, 4, 5, 4, 5, 4, 5, 1, 5, 4, 1, 3, 2, 2, 1, 5, 4, 5, 4, 4, 4, 4, 5, 1, 4, 4, 5, 5, 4, 4, 4, 1, 3, 5, 4, 3, 4, 4, 5, 4, 4, 4, 4, 4, 5, 5, 4, 4, 5, 5, 4, 4, 1, 3, 2, 2, 3, 5, 4, 5, 3, 4, 5, 4, 5, 5, 5, 3, 5, 5, 4, 5, 5, 1, 1, 2, 3, 1, 5, 5, 5, 5, 4, 3, 3, 3, 3, 3, 4, 3, 5, 1, 4, 5, 5, 1, 3, 3, 1, 4, 4, 4, 5, 4, 5, 3, 4, 4, 4, 4, 4, 5, 5, 5, 4, 5, 5, 5, 5, 3, 2, 2, 3, 5, 5, 4, 5, 4, 4, 4, 5, 4, 4, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 3, 3, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 4, 3, 3, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5]\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"test_eval_dataset_gl = []\nfor i in range(len(test_gl_dataset)):\n    test_eval_dataset_gl.append({\n        \"prompt\": test_gl_dataset[i][\"prompt\"],\n        \"response\": test_gl_dataset[i][\"completion\"]\n    })\n    \nreferencias_gl = get_references(test_eval_dataset_gl)\nprint(\"Referencias GL:\", referencias_gl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:19:58.731415Z","iopub.execute_input":"2025-12-22T00:19:58.732037Z","iopub.status.idle":"2025-12-22T00:19:58.761136Z","shell.execute_reply.started":"2025-12-22T00:19:58.732012Z","shell.execute_reply":"2025-12-22T00:19:58.760506Z"}},"outputs":[{"name":"stdout","text":"Referencias GL: [5, 5, 5, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 1, 5, 5, 5, 5, 5, 5, 4, 3, 5, 5, 4, 5, 5, 5, 5, 5, 3, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 5, 4, 5, 5, 5, 5, 5, 4, 4, 4, 3, 5, 5, 5, 1, 5, 5, 4, 3, 4, 5, 5, 5, 4, 5, 5, 5, 2, 4, 4, 4, 5, 5, 5, 4, 5, 5, 4, 4, 5, 5, 5, 5, 4, 4, 5, 5, 3, 4, 4, 1, 1, 5, 5, 5, 5, 5, 4, 5, 5, 1, 5, 5, 4, 4, 5, 5, 5, 2, 3, 5, 4, 5, 5, 5, 5, 4, 4, 4, 5, 1, 5, 5, 4, 4, 4, 5, 4, 3, 5, 5, 4, 5, 5]\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"# **EVALUO EL MODELO**","metadata":{}},{"cell_type":"code","source":"def evaluate_metric_model(model, dataset, tokenizer, metric):\n    all_predictions = []\n    model.eval()\n    all_predictions = []\n    all_references = []\n\n    \n    # Iterate over the dataset\n    for idx, example in enumerate(tqdm(dataset, desc=f\"Evaluating {metric} model\")):\n\n        prompt = example[\"prompt\"] \n        \n        inputs = tokenizer(\n            prompt,\n            return_tensors=\"pt\",\n            truncation=True,\n            max_length=5000,\n            padding=True\n        )\n        inputs = inputs.to(model.device)\n        with torch.no_grad():\n            outputs = model.generate(\n                input_ids=inputs[\"input_ids\"],\n                attention_mask=inputs[\"attention_mask\"],\n                max_new_tokens=50,\n                do_sample=False,  # GeneraciÃ³n determinista (greedy)\n                pad_token_id=tokenizer.eos_token_id\n            )\n        \n        prompt_length = len(inputs[\"input_ids\"][0])\n        new_tokens = outputs[0][prompt_length:]\n        generated_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n        match = re.search(r\"\\[FLUENCY\\]:\\s*(\\d+)\", generated_text)\n        print(generated_text)\n        if match:\n            all_predictions.append(float(match.group(1)))\n        else:\n            all_predictions.append(None)\n\n    \n    return all_predictions\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:19:58.761900Z","iopub.execute_input":"2025-12-22T00:19:58.762120Z","iopub.status.idle":"2025-12-22T00:19:58.780660Z","shell.execute_reply.started":"2025-12-22T00:19:58.762097Z","shell.execute_reply":"2025-12-22T00:19:58.780052Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"predictions_eu = evaluate_metric_model(model, test_eu_dataset,  tokenizer, \"Fluency\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:19:58.781616Z","iopub.execute_input":"2025-12-22T00:19:58.781890Z","iopub.status.idle":"2025-12-22T00:24:58.302653Z","shell.execute_reply.started":"2025-12-22T00:19:58.781852Z","shell.execute_reply":"2025-12-22T00:24:58.301993Z"}},"outputs":[{"name":"stderr","text":"Evaluating Fluency model:   1%|          | 1/198 [00:01<06:30,  1.98s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   1%|          | 2/198 [00:03<05:33,  1.70s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   2%|â–         | 3/198 [00:04<05:11,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   2%|â–         | 4/198 [00:06<04:58,  1.54s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   3%|â–         | 5/198 [00:08<05:13,  1.62s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   3%|â–         | 6/198 [00:13<09:03,  2.83s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n\n[FLUENCY]: 1\n[FLUENCY]: 1\n[FLUENCY]: 1\n[FLUENCY]: 1\n[FLUENC\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   4%|â–         | 7/198 [00:15<07:56,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   4%|â–         | 8/198 [00:16<07:06,  2.25s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   5%|â–         | 9/198 [00:18<06:31,  2.07s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   5%|â–Œ         | 10/198 [00:20<05:56,  1.90s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   6%|â–Œ         | 11/198 [00:21<05:44,  1.84s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   6%|â–Œ         | 12/198 [00:23<05:27,  1.76s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   7%|â–‹         | 13/198 [00:24<05:08,  1.67s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   7%|â–‹         | 14/198 [00:26<05:01,  1.64s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   8%|â–Š         | 15/198 [00:27<04:57,  1.62s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   8%|â–Š         | 16/198 [00:29<04:47,  1.58s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   9%|â–Š         | 17/198 [00:30<04:31,  1.50s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   9%|â–‰         | 18/198 [00:32<04:29,  1.50s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  10%|â–‰         | 19/198 [00:33<04:32,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  10%|â–ˆ         | 20/198 [00:35<04:28,  1.51s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  11%|â–ˆ         | 21/198 [00:36<04:14,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  11%|â–ˆ         | 22/198 [00:37<04:05,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  12%|â–ˆâ–        | 23/198 [00:39<04:16,  1.46s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  12%|â–ˆâ–        | 24/198 [00:41<04:24,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  13%|â–ˆâ–        | 25/198 [00:42<04:27,  1.54s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  13%|â–ˆâ–        | 26/198 [00:43<04:05,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  14%|â–ˆâ–        | 27/198 [00:45<04:03,  1.42s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  14%|â–ˆâ–        | 28/198 [00:46<04:01,  1.42s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  15%|â–ˆâ–        | 29/198 [00:49<05:03,  1.80s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  15%|â–ˆâ–Œ        | 30/198 [00:51<05:02,  1.80s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  16%|â–ˆâ–Œ        | 31/198 [00:52<04:55,  1.77s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  16%|â–ˆâ–Œ        | 32/198 [00:54<04:49,  1.74s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  17%|â–ˆâ–‹        | 33/198 [00:56<04:35,  1.67s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  17%|â–ˆâ–‹        | 34/198 [00:58<04:48,  1.76s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  18%|â–ˆâ–Š        | 35/198 [00:59<04:36,  1.70s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  18%|â–ˆâ–Š        | 36/198 [01:01<04:47,  1.77s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  19%|â–ˆâ–Š        | 37/198 [01:02<04:25,  1.65s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  19%|â–ˆâ–‰        | 38/198 [01:04<04:41,  1.76s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  20%|â–ˆâ–‰        | 39/198 [01:06<04:12,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  20%|â–ˆâ–ˆ        | 40/198 [01:07<04:13,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  21%|â–ˆâ–ˆ        | 41/198 [01:08<03:50,  1.47s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  21%|â–ˆâ–ˆ        | 42/198 [01:10<03:34,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  22%|â–ˆâ–ˆâ–       | 43/198 [01:11<03:35,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  22%|â–ˆâ–ˆâ–       | 44/198 [01:12<03:32,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  23%|â–ˆâ–ˆâ–       | 45/198 [01:14<03:33,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  23%|â–ˆâ–ˆâ–       | 46/198 [01:15<03:31,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  24%|â–ˆâ–ˆâ–       | 47/198 [01:17<03:40,  1.46s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  24%|â–ˆâ–ˆâ–       | 48/198 [01:18<03:33,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  25%|â–ˆâ–ˆâ–       | 49/198 [01:20<03:32,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  25%|â–ˆâ–ˆâ–Œ       | 50/198 [01:21<03:33,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  26%|â–ˆâ–ˆâ–Œ       | 51/198 [01:23<03:53,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  26%|â–ˆâ–ˆâ–‹       | 52/198 [01:24<03:42,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  27%|â–ˆâ–ˆâ–‹       | 53/198 [01:26<03:47,  1.57s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  27%|â–ˆâ–ˆâ–‹       | 54/198 [01:27<03:37,  1.51s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  28%|â–ˆâ–ˆâ–Š       | 55/198 [01:29<03:23,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  28%|â–ˆâ–ˆâ–Š       | 56/198 [01:30<03:20,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  29%|â–ˆâ–ˆâ–‰       | 57/198 [01:31<03:22,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 3\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  29%|â–ˆâ–ˆâ–‰       | 58/198 [01:33<03:11,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  30%|â–ˆâ–ˆâ–‰       | 59/198 [01:34<03:03,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  30%|â–ˆâ–ˆâ–ˆ       | 60/198 [01:35<02:54,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  31%|â–ˆâ–ˆâ–ˆ       | 61/198 [01:36<02:57,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  31%|â–ˆâ–ˆâ–ˆâ–      | 62/198 [01:38<02:49,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  32%|â–ˆâ–ˆâ–ˆâ–      | 63/198 [01:39<02:45,  1.23s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  32%|â–ˆâ–ˆâ–ˆâ–      | 64/198 [01:40<02:56,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  33%|â–ˆâ–ˆâ–ˆâ–      | 65/198 [01:42<03:02,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  33%|â–ˆâ–ˆâ–ˆâ–      | 66/198 [01:43<03:08,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  34%|â–ˆâ–ˆâ–ˆâ–      | 67/198 [01:45<03:09,  1.45s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  34%|â–ˆâ–ˆâ–ˆâ–      | 68/198 [01:46<03:17,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  35%|â–ˆâ–ˆâ–ˆâ–      | 69/198 [01:48<03:28,  1.62s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/198 [01:50<03:29,  1.64s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/198 [01:52<03:42,  1.75s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 72/198 [01:54<03:31,  1.68s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 73/198 [01:55<03:19,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/198 [01:56<03:15,  1.57s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/198 [01:58<03:06,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/198 [01:59<03:04,  1.51s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 77/198 [02:01<02:59,  1.49s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/198 [02:02<02:55,  1.46s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/198 [02:04<02:51,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/198 [02:05<02:42,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/198 [02:06<02:42,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 82/198 [02:08<02:44,  1.42s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/198 [02:09<02:36,  1.36s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/198 [02:10<02:29,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 85/198 [02:12<02:37,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 86/198 [02:13<02:38,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 87/198 [02:15<02:42,  1.46s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/198 [02:16<02:38,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/198 [02:18<02:54,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/198 [02:20<02:49,  1.57s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/198 [02:21<02:42,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 92/198 [02:22<02:30,  1.42s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/198 [02:24<02:31,  1.45s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/198 [02:25<02:29,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/198 [02:27<02:38,  1.54s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/198 [02:28<02:32,  1.49s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 97/198 [02:30<02:27,  1.46s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/198 [02:31<02:25,  1.46s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 99/198 [02:33<02:27,  1.48s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/198 [02:34<02:18,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/198 [02:36<02:27,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 102/198 [02:37<02:18,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/198 [02:38<02:11,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/198 [02:40<02:10,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 105/198 [02:41<02:03,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 106/198 [02:42<02:07,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 107/198 [02:44<02:10,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/198 [02:46<02:17,  1.53s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 109/198 [02:47<02:15,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/198 [02:52<03:34,  2.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n\n[FLUENCY]: 2\n[FLUENCY]: 3\n[FLUENCY]: 4\n[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/198 [02:53<03:07,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 112/198 [02:55<02:53,  2.02s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/198 [02:56<02:30,  1.77s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 114/198 [02:58<02:28,  1.76s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/198 [02:59<02:16,  1.65s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/198 [03:01<02:14,  1.64s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 117/198 [03:02<02:06,  1.56s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/198 [03:04<02:07,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 119/198 [03:05<02:02,  1.55s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/198 [03:07<02:04,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/198 [03:08<01:57,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 122/198 [03:10<01:52,  1.48s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/198 [03:11<01:48,  1.45s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/198 [03:13<01:47,  1.45s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 125/198 [03:14<01:41,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 126/198 [03:15<01:35,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 127/198 [03:16<01:34,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/198 [03:18<01:38,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 129/198 [03:19<01:35,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/198 [03:21<01:37,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/198 [03:22<01:35,  1.42s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 132/198 [03:24<01:35,  1.45s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/198 [03:25<01:33,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 134/198 [03:27<01:42,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/198 [03:29<01:38,  1.57s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/198 [03:30<01:38,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 137/198 [03:32<01:32,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/198 [03:34<01:40,  1.68s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 139/198 [03:35<01:33,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/198 [03:37<01:33,  1.62s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/198 [03:38<01:28,  1.55s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 142/198 [03:40<01:28,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 3\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/198 [03:41<01:23,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/198 [03:43<01:21,  1.50s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 145/198 [03:44<01:19,  1.50s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 146/198 [03:45<01:13,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 147/198 [03:47<01:11,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/198 [03:48<01:09,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 149/198 [03:49<01:07,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/198 [03:51<01:03,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 151/198 [03:52<01:03,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 152/198 [03:54<01:04,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/198 [03:55<01:02,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 154/198 [03:57<01:04,  1.47s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/198 [03:58<01:01,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 156/198 [04:00<01:03,  1.51s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 157/198 [04:01<01:01,  1.51s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/198 [04:03<01:02,  1.56s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 3\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 159/198 [04:05<01:06,  1.70s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 3\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/198 [04:06<01:01,  1.62s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 161/198 [04:08<00:59,  1.61s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 162/198 [04:10<01:03,  1.76s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/198 [04:11<00:56,  1.61s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/198 [04:13<00:55,  1.62s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 165/198 [04:14<00:51,  1.56s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 166/198 [04:16<00:53,  1.68s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 3\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 167/198 [04:18<00:49,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/198 [04:19<00:48,  1.62s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 169/198 [04:21<00:45,  1.55s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/198 [04:22<00:41,  1.50s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 171/198 [04:23<00:37,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 172/198 [04:25<00:37,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/198 [04:26<00:34,  1.36s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 174/198 [04:27<00:31,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/198 [04:28<00:30,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 176/198 [04:30<00:30,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 177/198 [04:31<00:28,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/198 [04:33<00:27,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 179/198 [04:34<00:26,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/198 [04:36<00:25,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 181/198 [04:37<00:23,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 182/198 [04:38<00:21,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/198 [04:39<00:19,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/198 [04:41<00:19,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 185/198 [04:42<00:17,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 186/198 [04:44<00:16,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 187/198 [04:45<00:14,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/198 [04:46<00:13,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 189/198 [04:48<00:12,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/198 [04:49<00:10,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 191/198 [04:50<00:09,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 192/198 [04:52<00:08,  1.36s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 3\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/198 [04:53<00:06,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 194/198 [04:54<00:05,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/198 [04:55<00:03,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 196/198 [04:57<00:02,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 197/198 [04:58<00:01,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198/198 [04:59<00:00,  1.51s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"print(\"EU test:\", predictions_eu)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:24:58.303558Z","iopub.execute_input":"2025-12-22T00:24:58.303766Z","iopub.status.idle":"2025-12-22T00:24:58.307942Z","shell.execute_reply.started":"2025-12-22T00:24:58.303743Z","shell.execute_reply":"2025-12-22T00:24:58.307251Z"}},"outputs":[{"name":"stdout","text":"EU test: [5.0, 4.0, 5.0, 5.0, 4.0, 1.0, 4.0, 1.0, 5.0, 4.0, 1.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 4.0, 5.0, 1.0, 5.0, 5.0, 1.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 1.0, 5.0, 1.0, 1.0, 5.0, 4.0, 4.0, 5.0, 1.0, 1.0, 5.0, 5.0, 4.0, 4.0, 1.0, 5.0, 1.0, 4.0, 4.0, 3.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 1.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 5.0, 1.0, 1.0, 5.0, 1.0, 1.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 1.0, 5.0, 5.0, 5.0, 1.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 3.0, 4.0, 5.0, 4.0, 5.0, 1.0, 5.0, 4.0, 5.0, 4.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 3.0, 3.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 3.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0]\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"cantidad_none = predictions_eu.count(None)\ntotal_eu = len(predictions_eu)\nporcentaje_eu = cantidad_none / total_eu\n\nprint(f\"Cantidad de valores None: {cantidad_none}, Total de predicciones: {total_eu}\")\nprint(f\"Porcentaje de Nones: {porcentaje_eu:.2%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:24:58.308864Z","iopub.execute_input":"2025-12-22T00:24:58.309104Z","iopub.status.idle":"2025-12-22T00:24:58.330136Z","shell.execute_reply.started":"2025-12-22T00:24:58.309065Z","shell.execute_reply":"2025-12-22T00:24:58.329580Z"}},"outputs":[{"name":"stdout","text":"Cantidad de valores None: 0, Total de predicciones: 198\nPorcentaje de Nones: 0.00%\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"## **QUITO LOS NONE**","metadata":{}},{"cell_type":"code","source":"filtrados = [(h, p) for h, p in zip(referencias_eu, predictions_eu) if h is not None and p is not None]\nhum_limpio, predictions_limpio = zip(*filtrados)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:24:58.330939Z","iopub.execute_input":"2025-12-22T00:24:58.331160Z","iopub.status.idle":"2025-12-22T00:24:58.346022Z","shell.execute_reply.started":"2025-12-22T00:24:58.331136Z","shell.execute_reply":"2025-12-22T00:24:58.345492Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"print(hum_limpio)\nprint(predictions_limpio)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:24:58.346889Z","iopub.execute_input":"2025-12-22T00:24:58.347167Z","iopub.status.idle":"2025-12-22T00:24:58.361482Z","shell.execute_reply.started":"2025-12-22T00:24:58.347132Z","shell.execute_reply":"2025-12-22T00:24:58.360965Z"}},"outputs":[{"name":"stdout","text":"(5, 3, 3, 5, 1, 2, 3, 2, 5, 5, 5, 5, 4, 5, 5, 4, 5, 4, 5, 4, 5, 1, 5, 4, 1, 3, 2, 2, 1, 5, 4, 5, 4, 4, 4, 4, 5, 1, 4, 4, 5, 5, 4, 4, 4, 1, 3, 5, 4, 3, 4, 4, 5, 4, 4, 4, 4, 4, 5, 5, 4, 4, 5, 5, 4, 4, 1, 3, 2, 2, 3, 5, 4, 5, 3, 4, 5, 4, 5, 5, 5, 3, 5, 5, 4, 5, 5, 1, 1, 2, 3, 1, 5, 5, 5, 5, 4, 3, 3, 3, 3, 3, 4, 3, 5, 1, 4, 5, 5, 1, 3, 3, 1, 4, 4, 4, 5, 4, 5, 3, 4, 4, 4, 4, 4, 5, 5, 5, 4, 5, 5, 5, 5, 3, 2, 2, 3, 5, 5, 4, 5, 4, 4, 4, 5, 4, 4, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 3, 3, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 4, 3, 3, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5)\n(5.0, 4.0, 5.0, 5.0, 4.0, 1.0, 4.0, 1.0, 5.0, 4.0, 1.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 4.0, 5.0, 1.0, 5.0, 5.0, 1.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 1.0, 5.0, 1.0, 1.0, 5.0, 4.0, 4.0, 5.0, 1.0, 1.0, 5.0, 5.0, 4.0, 4.0, 1.0, 5.0, 1.0, 4.0, 4.0, 3.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 1.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 5.0, 1.0, 1.0, 5.0, 1.0, 1.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 1.0, 5.0, 5.0, 5.0, 1.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 3.0, 4.0, 5.0, 4.0, 5.0, 1.0, 5.0, 4.0, 5.0, 4.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 3.0, 3.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 3.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0)\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## **MÃ‰TRICAS**","metadata":{}},{"cell_type":"markdown","source":"## **SPEARMANR**","metadata":{}},{"cell_type":"code","source":"# Mide si el modelo puede ordenar los modelos de peor a mejor \n# en comparaciÃ³n con las puntuaciones humanas (no exactamente la misma puntuaciÃ³n)\ns, p = spearmanr(hum_limpio, predictions_limpio)\nprint(f\"Spearman ES: {s:.3f}, p-value: {p:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:24:58.362250Z","iopub.execute_input":"2025-12-22T00:24:58.362524Z","iopub.status.idle":"2025-12-22T00:24:58.404527Z","shell.execute_reply.started":"2025-12-22T00:24:58.362500Z","shell.execute_reply":"2025-12-22T00:24:58.404000Z"}},"outputs":[{"name":"stdout","text":"Spearman ES: 0.389, p-value: 0.000\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"## **KENDALLTAU**","metadata":{}},{"cell_type":"code","source":"# Mide la capacidad para ordenar los resumenes segÃºn su calidad, \n# pero se calcula por parejas (de estos dos cuÃ¡l es el mejor?)\ntau, p_value = scipy.stats.kendalltau(hum_limpio, predictions_limpio)\nprint(f\"Kendalltau ES: {tau:.3f}, p-value: {p_value:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:24:58.405509Z","iopub.execute_input":"2025-12-22T00:24:58.405781Z","iopub.status.idle":"2025-12-22T00:24:58.436355Z","shell.execute_reply.started":"2025-12-22T00:24:58.405756Z","shell.execute_reply":"2025-12-22T00:24:58.435727Z"}},"outputs":[{"name":"stdout","text":"Kendalltau ES: 0.353, p-value: 0.000\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"## **MAE**","metadata":{}},{"cell_type":"code","source":"# Error medio absoluto\n# Mide la distancia media entre las puntuaciones predichas por los modelos \n# y las dadas por los humanos\n# Es decir, menos de 0,5 (ej.: humano -> 5, modelo -> 4.60)\nmae = np.mean(np.abs(np.array(hum_limpio) - np.array(predictions_limpio)))\nprint(f\"MAE ES: {mae}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:24:58.439158Z","iopub.execute_input":"2025-12-22T00:24:58.439459Z","iopub.status.idle":"2025-12-22T00:24:58.450998Z","shell.execute_reply.started":"2025-12-22T00:24:58.439408Z","shell.execute_reply":"2025-12-22T00:24:58.450266Z"}},"outputs":[{"name":"stdout","text":"MAE ES: 0.7676767676767676\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# **TEST GL**","metadata":{}},{"cell_type":"code","source":"predictions_gl = evaluate_metric_model(model, test_gl_dataset,  tokenizer, \"Fluency\")\nprint(\"GL test:\", predictions_gl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:24:58.451837Z","iopub.execute_input":"2025-12-22T00:24:58.452066Z","iopub.status.idle":"2025-12-22T00:28:20.394350Z","shell.execute_reply.started":"2025-12-22T00:24:58.452043Z","shell.execute_reply":"2025-12-22T00:28:20.393755Z"}},"outputs":[{"name":"stderr","text":"Evaluating Fluency model:   1%|          | 1/150 [00:01<03:27,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   1%|â–         | 2/150 [00:02<03:26,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   2%|â–         | 3/150 [00:04<03:16,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   3%|â–         | 4/150 [00:05<03:23,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 3\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   3%|â–         | 5/150 [00:06<03:21,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   4%|â–         | 6/150 [00:08<03:23,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   5%|â–         | 7/150 [00:09<03:13,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   5%|â–Œ         | 8/150 [00:11<03:13,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   6%|â–Œ         | 9/150 [00:12<03:04,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   7%|â–‹         | 10/150 [00:13<02:53,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   7%|â–‹         | 11/150 [00:14<03:05,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   8%|â–Š         | 12/150 [00:16<03:18,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   9%|â–Š         | 13/150 [00:17<03:15,  1.42s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:   9%|â–‰         | 14/150 [00:19<03:15,  1.44s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  10%|â–ˆ         | 15/150 [00:20<03:12,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  11%|â–ˆ         | 16/150 [00:22<03:11,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  11%|â–ˆâ–        | 17/150 [00:23<02:57,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  12%|â–ˆâ–        | 18/150 [00:24<02:58,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  13%|â–ˆâ–        | 19/150 [00:25<02:51,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  13%|â–ˆâ–        | 20/150 [00:27<02:45,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  14%|â–ˆâ–        | 21/150 [00:28<02:53,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  15%|â–ˆâ–        | 22/150 [00:30<02:58,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  15%|â–ˆâ–Œ        | 23/150 [00:31<02:51,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  16%|â–ˆâ–Œ        | 24/150 [00:32<02:52,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  17%|â–ˆâ–‹        | 25/150 [00:34<02:52,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  17%|â–ˆâ–‹        | 26/150 [00:35<02:52,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  18%|â–ˆâ–Š        | 27/150 [00:36<02:45,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  19%|â–ˆâ–Š        | 28/150 [00:38<02:49,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  19%|â–ˆâ–‰        | 29/150 [00:39<02:39,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  20%|â–ˆâ–ˆ        | 30/150 [00:40<02:30,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  21%|â–ˆâ–ˆ        | 31/150 [00:41<02:33,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  21%|â–ˆâ–ˆâ–       | 32/150 [00:43<02:38,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  22%|â–ˆâ–ˆâ–       | 33/150 [00:44<02:38,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  23%|â–ˆâ–ˆâ–       | 34/150 [00:46<02:40,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  23%|â–ˆâ–ˆâ–       | 35/150 [00:47<02:39,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  24%|â–ˆâ–ˆâ–       | 36/150 [00:49<02:40,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  25%|â–ˆâ–ˆâ–       | 37/150 [00:50<02:31,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  25%|â–ˆâ–ˆâ–Œ       | 38/150 [00:51<02:25,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  26%|â–ˆâ–ˆâ–Œ       | 39/150 [00:52<02:18,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  27%|â–ˆâ–ˆâ–‹       | 40/150 [00:53<02:16,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  27%|â–ˆâ–ˆâ–‹       | 41/150 [00:55<02:24,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  28%|â–ˆâ–ˆâ–Š       | 42/150 [00:56<02:28,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  29%|â–ˆâ–ˆâ–Š       | 43/150 [00:58<02:22,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  29%|â–ˆâ–ˆâ–‰       | 44/150 [00:59<02:23,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  30%|â–ˆâ–ˆâ–ˆ       | 45/150 [01:00<02:23,  1.36s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  31%|â–ˆâ–ˆâ–ˆ       | 46/150 [01:02<02:22,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  31%|â–ˆâ–ˆâ–ˆâ–      | 47/150 [01:03<02:15,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  32%|â–ˆâ–ˆâ–ˆâ–      | 48/150 [01:04<02:10,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  33%|â–ˆâ–ˆâ–ˆâ–      | 49/150 [01:05<02:06,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  33%|â–ˆâ–ˆâ–ˆâ–      | 50/150 [01:07<02:03,  1.23s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  34%|â–ˆâ–ˆâ–ˆâ–      | 51/150 [01:08<02:15,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  35%|â–ˆâ–ˆâ–ˆâ–      | 52/150 [01:10<02:23,  1.46s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 53/150 [01:11<02:23,  1.48s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 54/150 [01:13<02:20,  1.47s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 55/150 [01:14<02:17,  1.45s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 56/150 [01:16<02:14,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 57/150 [01:17<02:07,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 58/150 [01:18<02:06,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 59/150 [01:19<01:59,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 60/150 [01:21<01:55,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 61/150 [01:22<02:03,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 62/150 [01:24<02:08,  1.46s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 63/150 [01:25<02:01,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 64/150 [01:27<02:01,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 65/150 [01:28<01:59,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/150 [01:29<01:59,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 67/150 [01:31<01:53,  1.36s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 68/150 [01:32<01:54,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 69/150 [01:34<01:53,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 70/150 [01:35<01:47,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 71/150 [01:36<01:46,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 72/150 [01:38<01:47,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 73/150 [01:39<01:42,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 74/150 [01:40<01:43,  1.36s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 75/150 [01:42<01:42,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 76/150 [01:43<01:41,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 77/150 [01:44<01:34,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 78/150 [01:45<01:32,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 79/150 [01:47<01:28,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 80/150 [01:48<01:26,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 81/150 [01:49<01:28,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/150 [01:51<01:29,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 83/150 [01:52<01:25,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 84/150 [01:53<01:26,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 85/150 [01:55<01:27,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 86/150 [01:56<01:26,  1.36s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 87/150 [01:57<01:22,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 88/150 [01:58<01:19,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 89/150 [01:59<01:15,  1.23s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 90/150 [02:01<01:11,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 91/150 [02:02<01:16,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 92/150 [02:04<01:18,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 93/150 [02:05<01:17,  1.36s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 94/150 [02:06<01:16,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 95/150 [02:08<01:16,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 3\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 96/150 [02:09<01:15,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 97/150 [02:11<01:24,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 98/150 [02:13<01:21,  1.57s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 99/150 [02:14<01:14,  1.45s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 100/150 [02:15<01:08,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 101/150 [02:17<01:07,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 102/150 [02:18<01:07,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 103/150 [02:19<01:03,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 104/150 [02:21<01:02,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 3\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 105/150 [02:22<01:01,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 106/150 [02:23<01:01,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 107/150 [02:25<00:59,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 108/150 [02:26<00:56,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 109/150 [02:27<00:53,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 110/150 [02:28<00:50,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 111/150 [02:30<00:51,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 112/150 [02:31<00:52,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 113/150 [02:33<00:50,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 114/150 [02:34<00:50,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 115/150 [02:36<00:48,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 116/150 [02:37<00:47,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 117/150 [02:38<00:45,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 118/150 [02:40<00:44,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 119/150 [02:41<00:41,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 120/150 [02:42<00:38,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 121/150 [02:44<00:38,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 122/150 [02:45<00:38,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 123/150 [02:46<00:35,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 124/150 [02:47<00:33,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 125/150 [02:49<00:32,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 126/150 [02:50<00:31,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 127/150 [02:51<00:29,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 128/150 [02:53<00:28,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 129/150 [02:54<00:26,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 130/150 [02:55<00:24,  1.21s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 131/150 [02:56<00:24,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 132/150 [02:58<00:24,  1.36s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 133/150 [02:59<00:23,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 134/150 [03:01<00:22,  1.42s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 135/150 [03:02<00:21,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 136/150 [03:04<00:19,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 137/150 [03:05<00:18,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 138/150 [03:07<00:16,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 139/150 [03:08<00:14,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 140/150 [03:09<00:12,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 141/150 [03:10<00:11,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 142/150 [03:12<00:10,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 4\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 143/150 [03:13<00:08,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 144/150 [03:14<00:07,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 3\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 145/150 [03:15<00:06,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 146/150 [03:17<00:05,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 1\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 147/150 [03:18<00:03,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 148/150 [03:19<00:02,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 149/150 [03:20<00:01,  1.21s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Fluency model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [03:21<00:00,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[FLUENCY]: 5\nGL test: [5.0, 1.0, 4.0, 3.0, 1.0, 1.0, 4.0, 1.0, 5.0, 5.0, 5.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 1.0, 1.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 1.0, 4.0, 5.0, 5.0, 1.0, 1.0, 1.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 4.0, 1.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 5.0, 1.0, 4.0, 1.0, 5.0, 5.0, 5.0, 1.0, 4.0, 1.0, 1.0, 5.0, 1.0, 5.0, 4.0, 4.0, 5.0, 1.0, 4.0, 1.0, 5.0, 1.0, 1.0, 5.0, 4.0, 4.0, 5.0, 5.0, 3.0, 1.0, 5.0, 1.0, 5.0, 5.0, 4.0, 1.0, 1.0, 3.0, 4.0, 1.0, 4.0, 5.0, 4.0, 5.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 4.0, 4.0, 4.0, 1.0, 5.0, 1.0, 1.0, 5.0, 4.0, 1.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 1.0, 4.0, 1.0, 4.0, 1.0, 5.0, 5.0, 5.0, 4.0, 4.0, 5.0, 3.0, 1.0, 1.0, 5.0, 5.0, 5.0, 5.0]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"cantidad_none_gl = predictions_gl.count(None)\ntotal_gl = len(predictions_gl)\nporcentaje_gl = cantidad_none_gl / total_gl\n\nprint(f\"Cantidad de valores None: {cantidad_none_gl}, Total de predicciones: {total_gl}\")\nprint(f\"Porcentaje de Nones: {porcentaje_gl:.2%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:28:20.395304Z","iopub.execute_input":"2025-12-22T00:28:20.395574Z","iopub.status.idle":"2025-12-22T00:28:20.399971Z","shell.execute_reply.started":"2025-12-22T00:28:20.395547Z","shell.execute_reply":"2025-12-22T00:28:20.399340Z"}},"outputs":[{"name":"stdout","text":"Cantidad de valores None: 0, Total de predicciones: 150\nPorcentaje de Nones: 0.00%\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"## **QUITO LOS NONE**","metadata":{}},{"cell_type":"code","source":"filtrados_gl = [(h, p) for h, p in zip(referencias_gl, predictions_gl) if h is not None and p is not None]\nhum_limpio_gl, predictions_limpio_gl = zip(*filtrados_gl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:28:20.401409Z","iopub.execute_input":"2025-12-22T00:28:20.401688Z","iopub.status.idle":"2025-12-22T00:28:20.417883Z","shell.execute_reply.started":"2025-12-22T00:28:20.401663Z","shell.execute_reply":"2025-12-22T00:28:20.417156Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"print(hum_limpio_gl)\nprint(predictions_limpio_gl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:28:20.418942Z","iopub.execute_input":"2025-12-22T00:28:20.419486Z","iopub.status.idle":"2025-12-22T00:28:20.434486Z","shell.execute_reply.started":"2025-12-22T00:28:20.419450Z","shell.execute_reply":"2025-12-22T00:28:20.433932Z"}},"outputs":[{"name":"stdout","text":"(5, 5, 5, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 1, 5, 5, 5, 5, 5, 5, 4, 3, 5, 5, 4, 5, 5, 5, 5, 5, 3, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 5, 4, 5, 5, 5, 5, 5, 4, 4, 4, 3, 5, 5, 5, 1, 5, 5, 4, 3, 4, 5, 5, 5, 4, 5, 5, 5, 2, 4, 4, 4, 5, 5, 5, 4, 5, 5, 4, 4, 5, 5, 5, 5, 4, 4, 5, 5, 3, 4, 4, 1, 1, 5, 5, 5, 5, 5, 4, 5, 5, 1, 5, 5, 4, 4, 5, 5, 5, 2, 3, 5, 4, 5, 5, 5, 5, 4, 4, 4, 5, 1, 5, 5, 4, 4, 4, 5, 4, 3, 5, 5, 4, 5, 5)\n(5.0, 1.0, 4.0, 3.0, 1.0, 1.0, 4.0, 1.0, 5.0, 5.0, 5.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 1.0, 1.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 1.0, 4.0, 5.0, 5.0, 1.0, 1.0, 1.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 4.0, 1.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 5.0, 1.0, 4.0, 1.0, 5.0, 5.0, 5.0, 1.0, 4.0, 1.0, 1.0, 5.0, 1.0, 5.0, 4.0, 4.0, 5.0, 1.0, 4.0, 1.0, 5.0, 1.0, 1.0, 5.0, 4.0, 4.0, 5.0, 5.0, 3.0, 1.0, 5.0, 1.0, 5.0, 5.0, 4.0, 1.0, 1.0, 3.0, 4.0, 1.0, 4.0, 5.0, 4.0, 5.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 4.0, 4.0, 4.0, 1.0, 5.0, 1.0, 1.0, 5.0, 4.0, 1.0, 5.0, 5.0, 5.0, 5.0, 1.0, 5.0, 1.0, 4.0, 1.0, 4.0, 1.0, 5.0, 5.0, 5.0, 4.0, 4.0, 5.0, 3.0, 1.0, 1.0, 5.0, 5.0, 5.0, 5.0)\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"## **MÃ‰TRICAS**","metadata":{}},{"cell_type":"markdown","source":"## **SPEARMANR**","metadata":{}},{"cell_type":"code","source":"# Mide si el modelo puede ordenar los modelos de peor a mejor \n# en comparaciÃ³n con las puntuaciones humanas (no exactamente la misma puntuaciÃ³n)\ns, p = spearmanr(hum_limpio_gl, predictions_limpio_gl)\nprint(f\"Spearman GL: {s:.3f}, p-value: {p:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:28:20.435299Z","iopub.execute_input":"2025-12-22T00:28:20.435612Z","iopub.status.idle":"2025-12-22T00:28:20.452831Z","shell.execute_reply.started":"2025-12-22T00:28:20.435571Z","shell.execute_reply":"2025-12-22T00:28:20.452293Z"}},"outputs":[{"name":"stdout","text":"Spearman GL: 0.184, p-value: 0.024\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## **KENDALLTAU**","metadata":{}},{"cell_type":"code","source":"# Mide la capacidad para ordenar los resumenes segÃºn su calidad, \n# pero se calcula por parejas (de estos dos cuÃ¡l es el mejor?)\ntau, p_value = scipy.stats.kendalltau(hum_limpio_gl, predictions_limpio_gl)\nprint(f\"Kendalltau GL: {tau:.3f}, p-value: {p_value:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:28:20.453660Z","iopub.execute_input":"2025-12-22T00:28:20.454216Z","iopub.status.idle":"2025-12-22T00:28:20.471282Z","shell.execute_reply.started":"2025-12-22T00:28:20.454181Z","shell.execute_reply":"2025-12-22T00:28:20.470704Z"}},"outputs":[{"name":"stdout","text":"Kendalltau GL: 0.166, p-value: 0.024\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"## **MAE**","metadata":{}},{"cell_type":"code","source":"# Error medio absoluto\n# Mide la distancia media entre las puntuaciones predichas por los modelos \n# y las dadas por los humanos\n# Es decir, menos de 0,5 (ej.: humano -> 5, modelo -> 4.60)\nmae = np.mean(np.abs(np.array(hum_limpio_gl) - np.array(predictions_limpio_gl)))\nprint(f\"MAE GL: {mae}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:28:20.472172Z","iopub.execute_input":"2025-12-22T00:28:20.472651Z","iopub.status.idle":"2025-12-22T00:28:20.488203Z","shell.execute_reply.started":"2025-12-22T00:28:20.472625Z","shell.execute_reply":"2025-12-22T00:28:20.487722Z"}},"outputs":[{"name":"stdout","text":"MAE GL: 1.5266666666666666\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}